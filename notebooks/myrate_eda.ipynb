{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Freelance Profiles with relation to Hourly Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes to self:\n",
    "\n",
    "# The clustering on skills didn't work because there isn't enough skills per user.\n",
    "# Almost all users have about 5 skills, but there isn't enough overlap between them.\n",
    "# Futhermore, there is just about no signal relating the features to hourly rate.\n",
    "# Need to pivot and think of some alternative way to use this data.\n",
    "# Also, I need to figure out why everyone has a \"1\" for their invoices paid.\n",
    "\n",
    "# Do a regression tree model\n",
    "# Deriving other features from the text\n",
    "# Sentiment: Passive vs active voice?\n",
    "# do the skills appear in the text \n",
    "# Try a targeted search and get numerics out\n",
    "    # remove +'s' or try regex \n",
    "# Use text to look for those skills and maybe try to find words around it?\n",
    "# Skills in text vs not in the skill list \n",
    "# Naively do some kind of embedding (word2vec)\n",
    "    # Toss in their description and it creates a vector representation \n",
    "    # And then try looking at clusters in that space\n",
    "    # Specify the length of the vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Merging to get EDA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Packages for PostgreSQL Import and Export\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# Packages for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "\n",
    "# Packages for K-Modes Cluster\n",
    "import numpy as np\n",
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ideally I'll move this into the project config.py file\n",
    "# Otherwise for now I have to just manually assign . . .\n",
    "\n",
    "dbname = \"freelance_db\"\n",
    "username = \"Metaverse\"\n",
    "pswd = \"Arcifice91\"\n",
    "\n",
    "# Connect to Data\n",
    "con = None\n",
    "con = psycopg2.connect(database=dbname, user=username,\n",
    "                       host='localhost', password=pswd)\n",
    "\n",
    "# Checking shapes of tables\n",
    "sql_query = \"\"\"SELECT * from user_details_table;\"\"\"\n",
    "dtls_table = pd.read_sql_query(sql_query, con)\n",
    "\n",
    "sql_query = \"\"\"SELECT * from freelance_table;\"\"\"\n",
    "fl_table = pd.read_sql_query(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merging\n",
    "# Modifying profile_url in the details table so I can merge it with the fl_table\n",
    "dtls_table['profile_url'] = \"https://www.guru.com\"+dtls_table['profile_url']\n",
    "\n",
    "# Now I'm merging them together to make dt\n",
    "dt = pd.merge(fl_table, dtls_table, on='profile_url')\n",
    "dt.shape\n",
    "dt = dt.drop(columns=(['index_x']))\n",
    "dt = dt.drop_duplicates(subset='profile_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merging in data to crosswalk states with region labels\n",
    "state_region_crswlk = pd.read_csv(\n",
    "    '~/Desktop/Insight/projects/myrate/data/raw/census-regions/us census bureau regions and divisions.csv')\n",
    "state_region_crswlk.head()\n",
    "\n",
    "dt = pd.merge(dt, state_region_crswlk,\n",
    "              how='left', left_on='state', right_on='State')\n",
    "\n",
    "# Fixing region value for individuals living in Puerto Rico\n",
    "dt.loc[dt['state'] == \"Puerto Rico\", 'Region'] = \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Outcome: Hourly Rate\n",
    "### Beginning with investigating the geographic labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean hourly rate ($): 31.94\n"
     ]
    }
   ],
   "source": [
    "# What is the overall mean?\n",
    "print(\"Mean hourly rate ($):\", round(dt['hourly_rate'].mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean by region?\n",
    "dt.groupby(['Region']).hourly_rate.mean()\n",
    "\n",
    "# There is some variation, but it is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean across states?\n",
    "dt.groupby(['state']).hourly_rate.mean().sort_values().describe()\n",
    "\n",
    "# Pretty decent spread. This may be the most powerful signal yet.\n",
    "# If you print out hte full table it is clear that there is variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the variation within states?\n",
    "state_lvl_hourly_rate_descriptives = {}\n",
    "state_lvl_hourly_rate_descriptives['min'] = dt.groupby(\n",
    "    ['state']).hourly_rate.min()\n",
    "state_lvl_hourly_rate_descriptives['mean'] = dt.groupby(\n",
    "    ['state']).hourly_rate.mean()\n",
    "state_lvl_hourly_rate_descriptives['max'] = dt.groupby(\n",
    "    ['state']).hourly_rate.max()\n",
    "state_lvl_hourly_rate_descriptives['var'] = dt.groupby(\n",
    "    ['state']).hourly_rate.var()\n",
    "dt_state_hr = pd.DataFrame(state_lvl_hourly_rate_descriptives)\n",
    "\n",
    "# A decent amount of variation within the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I tried to break it down further to the city level\n",
    "# But the city data is really messy and not worth the time sink\n",
    "# To try and get it set up. The idea would be to merge on\n",
    "# rural vs urban and see if it can help me filter out a signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the relationship between a users \"rating\" and the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaing it up real quick\n",
    "dt.rating = dt.rating.str.replace('%', '')\n",
    "dt.rating = dt.rating.str.replace('NA', '')\n",
    "dt.rating = pd.to_numeric(dt.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with Missing Values\n",
    "print(\"Number of missing values: \", dt.rating.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the spread look like for the rest?\n",
    "dt.rating.describe()\n",
    "\n",
    "# Basically no variation. Okay, let's make a binary variable (has_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_rating\n",
       "0    34.529412\n",
       "1    31.743139\n",
       "Name: hourly_rate, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating \"has_rating\"\n",
    "dt['has_rating'] = None\n",
    "dt.loc[dt['rating'].isna(), 'has_rating'] = 0\n",
    "dt.loc[dt['rating'] > 0, 'has_rating'] = 1\n",
    "\n",
    "# Comparing outcome means by has_rating\n",
    "dt.groupby(['has_rating']).hourly_rate.mean()\n",
    "\n",
    "# Small difference, nothing substantial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the duration of membership and hourly rate\n",
    "\n",
    "1. Convert member start date to a date object\n",
    "2. Calculate years / months they've been a member (to today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_convert(member_since):\n",
    "    try:\n",
    "        tmp = datetime.strptime(member_since, '%b, %Y')\n",
    "        #tmp = tmp.strftime('%Y-%m')\n",
    "    except:\n",
    "        tmp = 'NaN'\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_active(date):\n",
    "    cur_year = datetime.now().year\n",
    "    try:\n",
    "        yrs_active = cur_year - date.year\n",
    "    except:\n",
    "        yrs_active = 'NaN'\n",
    "\n",
    "    return yrs_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_active(date):\n",
    "    cur_year = datetime.now().year\n",
    "    cur_month = datetime.now().month\n",
    "\n",
    "    try:\n",
    "        mnths_active = (cur_year - date.year)*12 + (cur_month - date.month)\n",
    "    except:\n",
    "        mnths_active = 'NaN'\n",
    "\n",
    "    return mnths_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting member_since to date\n",
    "dt.member_since = dt.member_since.str.strip()\n",
    "dt['start_date'] = dt.member_since.apply(date_convert)\n",
    "dt['years_active'] = dt.start_date.apply(years_active)\n",
    "dt['months_active'] = dt.start_date.apply(months_active)\n",
    "\n",
    "# Therea are 31 NAs. Just going to ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "years_active\n",
       "0.0     30.869565\n",
       "1.0     32.279570\n",
       "2.0     31.409091\n",
       "3.0     31.804598\n",
       "4.0     30.594203\n",
       "5.0     30.295775\n",
       "6.0     29.396552\n",
       "7.0     23.527778\n",
       "8.0     31.758621\n",
       "9.0     24.173913\n",
       "10.0    28.482759\n",
       "11.0    28.192308\n",
       "12.0    34.178571\n",
       "13.0    32.521739\n",
       "14.0    37.481481\n",
       "15.0    38.652174\n",
       "16.0    32.541667\n",
       "17.0    51.190476\n",
       "18.0    39.384615\n",
       "19.0    42.533333\n",
       "20.0    55.000000\n",
       "Name: hourly_rate, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What I want to understand is:\n",
    "# How does the hourly rate (average) change across years active?\n",
    "dt.groupby('years_active').hourly_rate.mean()\n",
    "\n",
    "# Nothing much. It ramps up if years active > 17. Building that binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['active_17up'] = (dt['years_active'] >= 17) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay let's try looking at months active. Maybe on a finer scale there is some difference?\n",
    "x = dt.groupby('months_active').hourly_rate.mean().index\n",
    "y = dt.groupby('months_active').hourly_rate.mean()\n",
    "ax = sns.scatterplot(x=x, y=y,\n",
    "                     color='black')\n",
    "ax.set(xlabel='months_active', ylabel='Average hourly_rate')\n",
    "plt.show()\n",
    "\n",
    "# No real pattern emerges. Unfortunately not useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring hourly rate and how it relates to the skills\n",
    "\n",
    "1. Obtain the dataset that is long by skills and shrink it down to just the skills. I'll work with that for this.\n",
    "2. Create some quick features such as: # of skills and top skill. These are user level so I can attach them back to dt to have everything in one place.\n",
    "\n",
    "Note: the skills are standardized on guru which makes this more straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_query = \"\"\"SELECT profile_url, skills_list from freelance_table;\"\"\"\n",
    "skills_table = pd.read_sql_query(sql_query, con)\n",
    "skills_table_dummies = pd.get_dummies(skills_table, columns=[\n",
    "                                      'skills_list'], prefix='').groupby(['profile_url']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of skills\n",
    "num_skills = skills_table.groupby('profile_url').count()\n",
    "num_skills = num_skills.rename(columns={\"skills_list\": \"num_skills\"})\n",
    "num_skills = num_skills.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging num skills into dt\n",
    "dt = pd.merge(dt, num_skills, on=\"profile_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_skills\n",
       "1    25.620690\n",
       "2    42.600000\n",
       "3    27.750000\n",
       "4    24.381818\n",
       "5    32.415854\n",
       "Name: hourly_rate, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.groupby('num_skills').hourly_rate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems that for those with less than five skills listed\n",
    "# they tend to have a lower hourly rate.\n",
    "dt['less_five_skills'] = (dt['num_skills'] < 5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving on to something else. Let's look at the top skills (first skill listed)\n",
    "first_skill = skills_table[skills_table.groupby(\n",
    "    'profile_url')['skills_list'].cumcount() == 0]\n",
    "\n",
    "first_skill = first_skill.rename(\n",
    "    columns={\"profile_url\": \"profile_url\", \"skills_list\": \"first_skill\"})\n",
    "\n",
    "dt = pd.merge(dt, first_skill, on=\"profile_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique skills:  350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    350.000000\n",
       "mean       2.797143\n",
       "std        4.245543\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        2.000000\n",
       "max       32.000000\n",
       "Name: first_skill, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring First Skills\n",
    "print(\"Number of unique skills: \", dt.first_skill.nunique())\n",
    "dt.groupby('first_skill').first_skill.count().describe()\n",
    "\n",
    "# There is some repition but not much. Maybe I can get something off the extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring extreme first skill frequencies\n",
    "skill_freq = {}\n",
    "skill_freq['skill_frequency'] = dt.groupby(\n",
    "    'first_skill').first_skill.count().sort_values(ascending=False)\n",
    "skill_freq['skills_list'] = dt.groupby(\n",
    "    'first_skill').first_skill.count().sort_values(ascending=False).index\n",
    "skill_freq = pd.DataFrame(skill_freq)\n",
    "skill_freq = skill_freq.reset_index()\n",
    "skill_freq = skill_freq.drop(['first_skill'], axis=1)\n",
    "\n",
    "dt = pd.merge(dt, skill_freq, on=\"skills_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='skill_frequency', y='hourly_rate', data=dt)\n",
    "\n",
    "# Nope, not much of anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just have to try to keep thinking of ways I could use this information.\n",
    "# Ideally, I would be able to go group them by category and calculate hourly rate on that\n",
    "# There may also be an interaction effect occuring between the category and something like\n",
    "# years of experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the process of using the \"bio\" data\n",
    "\n",
    "1. The easiest variable to create is the len(bio)\n",
    "2. I'll have to try and expand it more using some other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bio(bio):\n",
    "    try:\n",
    "        cleaned_bio = ''.join(s for s in bio if ord(s) > 31 and ord(s) < 126)\n",
    "    except:\n",
    "        cleaned_bio = \"NaN\"\n",
    "    return cleaned_bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_bio(bio):\n",
    "    if bio == \"NaN\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average word length in bio\n",
    "def avg_word_ln(bio):\n",
    "    try:\n",
    "        words = bio.split()\n",
    "        res = (sum(len(word) for word in words)/len(words))\n",
    "    except:\n",
    "        res = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stop words\n",
    "def num_stopwords(bio):\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    try:\n",
    "        res = len([x for x in bio.split() if x in stop])\n",
    "    except:\n",
    "        res = -1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['bio_clean'] = dt.bio.apply(clean_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['bio_length'] = dt.bio_clean.apply(len_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Hi how are you doing today\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of separate words in bio\n",
    "dt['bio_word_count'] = dt['bio_clean'].apply(\n",
    "    lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['avg_word_length'] = dt['bio_clean'].apply(avg_word_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['num_stop'] = dt['bio_clean'].apply(num_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing before pulling more features\n",
    "\n",
    "# Remvoing stop words\n",
    "stop = stopwords.words('english')\n",
    "dt['bio_processed'] = dt['bio_clean'].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# Removing punctuation\n",
    "dt['bio_processed'] = dt['bio_processed'].str.replace(\n",
    "    '[^\\w\\s]', '')\n",
    "\n",
    "# Lower Case\n",
    "dt['bio_processed'] = dt['bio_processed'].apply(\n",
    "    lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring how these bio features related to hourly rate\n",
    "\n",
    "# Starting with the length of a users bio\n",
    "sns.scatterplot(x='bio_length', y='hourly_rate', data=dt)\n",
    "\n",
    "# Nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about how the word count related to hourly rate?\n",
    "sns.scatterplot(x='bio_word_count', y='hourly_rate', data=dt)\n",
    "\n",
    "# Nope, again nothing of interest here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, what about how word length\n",
    "sns.scatterplot(x='hourly_rate', y='avg_word_length', data=dt)\n",
    "\n",
    "# Hmm, no. But there are some very unusual outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lastly, the number of stop words\n",
    "sns.scatterplot(x='num_stop', y='hourly_rate', data=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole lot of nothing came out of the bio features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing number of employers and hourly rate\n",
    "\n",
    "Nevermind. There is no variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making State dummy variables\n",
    "state_dummies = pd.get_dummies(dt['state'])\n",
    "dt = pd.concat([dt, state_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earnings per Month\n",
    "dt['earnings_ever'] = dt['earnings_ever'].str.replace('$', '')\n",
    "dt['earnings_ever'] = dt['earnings_ever'].str.replace(',', '')\n",
    "dt['earnings_ever'] = pd.to_numeric(dt['earnings_ever'])\n",
    "dt['earnings_pr_month'] = dt['earnings_ever'] / \\\n",
    "    dt['months_active']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Skills and Labels\n",
    "\n",
    "### Goal: Merge scraped skills list and categories into data based on user reported skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"SELECT * from skills_categories_table;\"\"\"\n",
    "sk_table = pd.read_sql_query(sql_query, con)\n",
    "sk_table = sk_table.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Numbers\n",
    "sk_table['Skill_Frequency'] = pd.to_numeric(sk_table.Skills.str.extract(\n",
    "    r'\\((\\d*?)\\)').iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Columns of frequency labels\n",
    "sk_table['Skills_Clean'] = sk_table.Skills.str.replace(\n",
    "    r'\\((\\d*?)\\)','').str.strip().str.lower()\n",
    "sk_table['Category'] = sk_table.Category.str.replace(\n",
    "    r'\\((.*?)\\)','').str.strip().str.lower()\n",
    "sk_table['Subcategory'] = sk_table.Subcategory.str.replace(\n",
    "    r'\\((\\d*?)\\)','').str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in the user skills table\n",
    "sql_query = \"\"\"SELECT profile_url, skills_list from freelance_table;\"\"\"\n",
    "skills_table = pd.read_sql_query(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_table['skills_list'] = skills_table['skills_list'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.merge(skills_table,sk_table,\n",
    "               left_on='skills_list',right_on='Skills_Clean', how=\"left\",\n",
    "               indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to try and see how many people match\n",
    "# If they matched on at least one thing I can then expand that onto the rest of their data\n",
    "tmp['matched'] = (tmp['_merge'] == \"both\") * 1\n",
    "number_of_matches_by_user = tmp.groupby(['profile_url']).matched.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(number_of_matches_by_user == 0).sum()\n",
    "\n",
    "# This is great, a good chunk of people matched.\n",
    "# Now I can guess what field they were in (for the ones who matched)\n",
    "# and then label the people similar to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['num_matched'] = tmp.groupby(['profile_url']).matched.transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So for people who matched, I want to determine which category most common for them\n",
    "test = tmp[tmp['num_matched'] > 0][['profile_url','Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>administrative &amp; secretarial</th>\n",
       "      <th>business &amp; finance</th>\n",
       "      <th>design &amp; art</th>\n",
       "      <th>education &amp; training</th>\n",
       "      <th>engineering &amp; architecture</th>\n",
       "      <th>legal</th>\n",
       "      <th>programming &amp; development</th>\n",
       "      <th>sales &amp; marketing</th>\n",
       "      <th>writing &amp; translation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/35-year-editor-has-your-back</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/86-keys-communications</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/a-stringham</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/a-wordsmith</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/aa-consultants</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category                                            administrative & secretarial  \\\n",
       "profile_url                                                                        \n",
       "https://www.guru.com/freelancers/35-year-editor...                             0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                             0   \n",
       "https://www.guru.com/freelancers/a-stringham                                   2   \n",
       "https://www.guru.com/freelancers/a-wordsmith                                   0   \n",
       "https://www.guru.com/freelancers/aa-consultants                                0   \n",
       "\n",
       "Category                                            business & finance  \\\n",
       "profile_url                                                              \n",
       "https://www.guru.com/freelancers/35-year-editor...                   0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                   0   \n",
       "https://www.guru.com/freelancers/a-stringham                         0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                         0   \n",
       "https://www.guru.com/freelancers/aa-consultants                      1   \n",
       "\n",
       "Category                                            design & art  \\\n",
       "profile_url                                                        \n",
       "https://www.guru.com/freelancers/35-year-editor...             0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...             0   \n",
       "https://www.guru.com/freelancers/a-stringham                   0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                   0   \n",
       "https://www.guru.com/freelancers/aa-consultants                0   \n",
       "\n",
       "Category                                            education & training  \\\n",
       "profile_url                                                                \n",
       "https://www.guru.com/freelancers/35-year-editor...                     0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                     0   \n",
       "https://www.guru.com/freelancers/a-stringham                           0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                           0   \n",
       "https://www.guru.com/freelancers/aa-consultants                        0   \n",
       "\n",
       "Category                                            engineering & architecture  \\\n",
       "profile_url                                                                      \n",
       "https://www.guru.com/freelancers/35-year-editor...                           0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                           0   \n",
       "https://www.guru.com/freelancers/a-stringham                                 0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                                 0   \n",
       "https://www.guru.com/freelancers/aa-consultants                              0   \n",
       "\n",
       "Category                                            legal  \\\n",
       "profile_url                                                 \n",
       "https://www.guru.com/freelancers/35-year-editor...      0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...      0   \n",
       "https://www.guru.com/freelancers/a-stringham            0   \n",
       "https://www.guru.com/freelancers/a-wordsmith            0   \n",
       "https://www.guru.com/freelancers/aa-consultants         0   \n",
       "\n",
       "Category                                            programming & development  \\\n",
       "profile_url                                                                     \n",
       "https://www.guru.com/freelancers/35-year-editor...                          0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                          0   \n",
       "https://www.guru.com/freelancers/a-stringham                                0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                                0   \n",
       "https://www.guru.com/freelancers/aa-consultants                             2   \n",
       "\n",
       "Category                                            sales & marketing  \\\n",
       "profile_url                                                             \n",
       "https://www.guru.com/freelancers/35-year-editor...                  0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                  0   \n",
       "https://www.guru.com/freelancers/a-stringham                        0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                        0   \n",
       "https://www.guru.com/freelancers/aa-consultants                     0   \n",
       "\n",
       "Category                                            writing & translation  \n",
       "profile_url                                                                \n",
       "https://www.guru.com/freelancers/35-year-editor...                      5  \n",
       "https://www.guru.com/freelancers/86-keys-commun...                      2  \n",
       "https://www.guru.com/freelancers/a-stringham                            1  \n",
       "https://www.guru.com/freelancers/a-wordsmith                            2  \n",
       "https://www.guru.com/freelancers/aa-consultants                         0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping wide\n",
    "# test['counter'] = test.groupby(['profile_url']).cumcount()+1\n",
    "test['counter'] = 1\n",
    "skill_category_matrix = test.pivot_table(index = 'profile_url', columns = 'Category', \n",
    "                     values = 'counter', aggfunc = 'sum', \n",
    "                     fill_value = 0)\n",
    "skill_category_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Update: Working with Skill Categories\n",
    "\n",
    "1. I now have a user-level matrix with the skill categories along the top\n",
    "2. I also have a user-level matrix with skill categories along the top but with missing data.\n",
    "3. I want to impute that matrix. How?\n",
    "4. The simplest way would be to create the **very** wide skill matrix and do lookups for similarity.\n",
    "    - For example, take skills vector (long, 0/1s) of user A who I want to impute his categories. Find the most similar vector among the users with data. Impute from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First resetting index on skill_category_matrix\n",
    "skill_category_matrix = skill_category_matrix.reset_index()\n",
    "skill_category_matrix['has_categories'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And creating skills dummy matrix\n",
    "sql_query = \"\"\"SELECT profile_url, skills_list from freelance_table;\"\"\"\n",
    "skills_table = pd.read_sql_query(sql_query, con)\n",
    "skills_table_dummies = pd.get_dummies(skills_table, columns=[\n",
    "                                      'skills_list'], prefix='').groupby(['profile_url']).sum()\n",
    "skills_table_dummies = skills_table_dummies.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And merging\n",
    "skills_table_dummies = pd.merge(skills_table_dummies, \n",
    "                                skill_category_matrix.loc[:,['profile_url','has_categories']], \n",
    "                                left_on = 'profile_url',\n",
    "                                right_on = 'profile_url',\n",
    "                                how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the NA has_categories so it's a useful indicator\n",
    "skills_table_dummies['has_categories'] = skills_table_dummies['has_categories'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cat = skills_table_dummies[skills_table_dummies['has_categories'] == 1]\n",
    "no_cat = skills_table_dummies[skills_table_dummies['has_categories'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_distance():\n",
    "    sqrdist = np.sum(np.sqrt(np.square(user_no_cat-user_has_cat)))\n",
    "    return sqrdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "# Creating one long list of all distances\n",
    "dist = []\n",
    "for k in range(0,no_cat.shape[0]):\n",
    "    if k%50 == 0 :\n",
    "        print(k) \n",
    "    for j in range(0,has_cat.shape[0]):\n",
    "        user_no_cat = np.array(list(no_cat.iloc[k,1:]))\n",
    "        user_has_cat = np.array(list(has_cat.iloc[j,1:]))\n",
    "        dist.append(raw_distance())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting that list into a numpy matrix of the appropriate shape\n",
    "res = np.array(dist).reshape(no_cat.shape[0],has_cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding where the FIRST minimum is for each user\n",
    "# Come back later and clean this up to return multiple minimums\n",
    "# Making my life easy for now . . .\n",
    "min_indices = np.argmin(res, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to take the minimum index and use it on the has_cat table\n",
    "# to look up the person with whom they have similar relationship.\n",
    "# I can then extract this users row and slap it into a new table (impute_cat)\n",
    "cols = list(skill_category_matrix.columns)[0:10]\n",
    "impute_cat = pd.DataFrame(columns=cols)\n",
    "\n",
    "impute_cat['profile_url'] = no_cat['profile_url']\n",
    "\n",
    "for j in range(0,no_cat.shape[0]):\n",
    "    impute_cat.iloc[j,1:] = skill_category_matrix.iloc[min_indices[j],1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to skill_category_matrix\n",
    "full_cat = skill_category_matrix.append(impute_cat)\n",
    "full_cat = full_cat.drop(['has_categories'], axis = 1)\n",
    "full_cat = full_cat.fillna(0)\n",
    "# Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this out so I don't have to run the calculation again . . .\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s' %\n",
    "                       (username, pswd, dbname))\n",
    "full_cat.to_sql(\"full_cat_dt\", engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill Categories Update #2\n",
    "\n",
    "1. I imputed the skill categories using the L2 norm to find similar users\n",
    "2. Now I have a user level matrix with the skill category and the number of skills they have in it.\n",
    "3. However, the number is a little misleading because sometimes they just didn't match on their other listed skills.\n",
    "4. Therefore, I now have the question of:\n",
    "    - Do I create dummies for whether or not they have a certain category, at all?\n",
    "    - Or do I pick the one they have the largest value in?\n",
    "    - I think I may just do dummies for now. This means I just need to make any value > 0 = 1\n",
    "5. Anyways, the next step is to explore the mean hourly_rate by skill categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging it into the data\n",
    "dt = pd.merge(dt, full_cat, on=\"profile_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Binary Dummies\n",
    "cols = list(dt.columns[-9:])\n",
    "for j in range(0,len(cols)):\n",
    "    dt.loc[dt[cols[j]] > 0, cols[j]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the relationship between skill categories and hourly rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(cols)):\n",
    "    print(dt.groupby(cols[j]).hourly_rate.mean())\n",
    "    \n",
    "# For Engineering, Legal, programming, there is a marked difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving out Modified Dataset\n",
    "\n",
    "1. First printing the columns I have for reference.\n",
    "2. Saving it to a new table in the postgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_url</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "      <th>earnings</th>\n",
       "      <th>hourly_rate</th>\n",
       "      <th>skills_list</th>\n",
       "      <th>user_description</th>\n",
       "      <th>index_y</th>\n",
       "      <th>...</th>\n",
       "      <th>earnings_pr_month</th>\n",
       "      <th>administrative &amp; secretarial</th>\n",
       "      <th>business &amp; finance</th>\n",
       "      <th>design &amp; art</th>\n",
       "      <th>education &amp; training</th>\n",
       "      <th>engineering &amp; architecture</th>\n",
       "      <th>legal</th>\n",
       "      <th>programming &amp; development</th>\n",
       "      <th>sales &amp; marketing</th>\n",
       "      <th>writing &amp; translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.guru.com/freelancers/scopic</td>\n",
       "      <td>Rutland</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>United States</td>\n",
       "      <td>100.0</td>\n",
       "      <td>$1,338,285/year</td>\n",
       "      <td>24</td>\n",
       "      <td>Angular</td>\n",
       "      <td>Scopic Software offers high-quality and afford...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27750.980296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.guru.com/freelancers/crazy-program...</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>United States</td>\n",
       "      <td>100.0</td>\n",
       "      <td>$110,080/year</td>\n",
       "      <td>60</td>\n",
       "      <td>Angular</td>\n",
       "      <td>I am a full stack web developer with much expe...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12018.885714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.guru.com/freelancers/andrii-tsyniuk</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Texas</td>\n",
       "      <td>United States</td>\n",
       "      <td>100.0</td>\n",
       "      <td>$45,320/year</td>\n",
       "      <td>50</td>\n",
       "      <td>Angular</td>\n",
       "      <td>Javascript developer with 8 years of experienc...</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>6474.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.guru.com/freelancers/tyler-william...</td>\n",
       "      <td>Fort Collins</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$8,000/year</td>\n",
       "      <td>55</td>\n",
       "      <td>Angular</td>\n",
       "      <td>I am a full-stack web engineer with over 7+ ye...</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>579.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.guru.com/freelancers/jonathan-ryan...</td>\n",
       "      <td>Hamilton Township</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>United States</td>\n",
       "      <td>100.0</td>\n",
       "      <td>$4,400/year</td>\n",
       "      <td>70</td>\n",
       "      <td>Angular</td>\n",
       "      <td>I am available to write custom websites and ap...</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>162.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         profile_url               city  \\\n",
       "0            https://www.guru.com/freelancers/scopic            Rutland   \n",
       "1  https://www.guru.com/freelancers/crazy-program...            Hammond   \n",
       "2    https://www.guru.com/freelancers/andrii-tsyniuk        San Antonio   \n",
       "3  https://www.guru.com/freelancers/tyler-william...       Fort Collins   \n",
       "4  https://www.guru.com/freelancers/jonathan-ryan...  Hamilton Township   \n",
       "\n",
       "           state        country  rating         earnings  hourly_rate  \\\n",
       "0  Massachusetts  United States   100.0  $1,338,285/year           24   \n",
       "1      Louisiana  United States   100.0    $110,080/year           60   \n",
       "2          Texas  United States   100.0     $45,320/year           50   \n",
       "3       Colorado  United States     NaN      $8,000/year           55   \n",
       "4     New Jersey  United States   100.0      $4,400/year           70   \n",
       "\n",
       "  skills_list                                   user_description  index_y  \\\n",
       "0     Angular  Scopic Software offers high-quality and afford...        0   \n",
       "1     Angular  I am a full stack web developer with much expe...        5   \n",
       "2     Angular  Javascript developer with 8 years of experienc...       15   \n",
       "3     Angular  I am a full-stack web engineer with over 7+ ye...       19   \n",
       "4     Angular  I am available to write custom websites and ap...       18   \n",
       "\n",
       "   ... earnings_pr_month administrative & secretarial  business & finance  \\\n",
       "0  ...      27750.980296                            0                   0   \n",
       "1  ...      12018.885714                            0                   0   \n",
       "2  ...       6474.285714                            0                   0   \n",
       "3  ...        579.875000                            0                   0   \n",
       "4  ...        162.500000                            0                   0   \n",
       "\n",
       "  design & art education & training engineering & architecture legal  \\\n",
       "0            0                    0                          0     0   \n",
       "1            0                    0                          0     0   \n",
       "2            0                    0                          0     0   \n",
       "3            0                    0                          0     0   \n",
       "4            0                    0                          0     0   \n",
       "\n",
       "  programming & development sales & marketing writing & translation  \n",
       "0                         0                 1                     0  \n",
       "1                         1                 0                     0  \n",
       "2                         0                 1                     0  \n",
       "3                         1                 0                     0  \n",
       "4                         1                 0                     0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 979 entries, 0 to 978\n",
      "Data columns (total 96 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   profile_url                   979 non-null    object        \n",
      " 1   city                          979 non-null    object        \n",
      " 2   state                         979 non-null    object        \n",
      " 3   country                       979 non-null    object        \n",
      " 4   rating                        911 non-null    float64       \n",
      " 5   earnings                      979 non-null    object        \n",
      " 6   hourly_rate                   979 non-null    int64         \n",
      " 7   skills_list                   979 non-null    object        \n",
      " 8   user_description              979 non-null    object        \n",
      " 9   index_y                       979 non-null    int64         \n",
      " 10  member_since                  979 non-null    object        \n",
      " 11  earnings_pst_yr               948 non-null    object        \n",
      " 12  earnings_ever                 948 non-null    float64       \n",
      " 13  employers                     948 non-null    object        \n",
      " 14  invoices_paid                 948 non-null    object        \n",
      " 15  largest_employ                948 non-null    object        \n",
      " 16  bio                           948 non-null    object        \n",
      " 17  State                         975 non-null    object        \n",
      " 18  State Code                    975 non-null    object        \n",
      " 19  Region                        979 non-null    object        \n",
      " 20  Division                      975 non-null    object        \n",
      " 21  has_rating                    979 non-null    object        \n",
      " 22  start_date                    948 non-null    datetime64[ns]\n",
      " 23  years_active                  948 non-null    float64       \n",
      " 24  months_active                 948 non-null    float64       \n",
      " 25  active_17up                   979 non-null    int64         \n",
      " 26  num_skills                    979 non-null    int64         \n",
      " 27  less_five_skills              979 non-null    int64         \n",
      " 28  first_skill                   979 non-null    object        \n",
      " 29  skill_frequency               979 non-null    int64         \n",
      " 30  bio_clean                     979 non-null    object        \n",
      " 31  bio_length                    979 non-null    int64         \n",
      " 32  bio_word_count                979 non-null    int64         \n",
      " 33  avg_word_length               979 non-null    float64       \n",
      " 34  num_stop                      979 non-null    int64         \n",
      " 35  bio_processed                 979 non-null    object        \n",
      " 36  Alabama                       979 non-null    uint8         \n",
      " 37  Arizona                       979 non-null    uint8         \n",
      " 38  Arkansas                      979 non-null    uint8         \n",
      " 39  California                    979 non-null    uint8         \n",
      " 40  Colorado                      979 non-null    uint8         \n",
      " 41  Connecticut                   979 non-null    uint8         \n",
      " 42  Delaware                      979 non-null    uint8         \n",
      " 43  District of Columbia          979 non-null    uint8         \n",
      " 44  Florida                       979 non-null    uint8         \n",
      " 45  Georgia                       979 non-null    uint8         \n",
      " 46  Idaho                         979 non-null    uint8         \n",
      " 47  Illinois                      979 non-null    uint8         \n",
      " 48  Indiana                       979 non-null    uint8         \n",
      " 49  Iowa                          979 non-null    uint8         \n",
      " 50  Kansas                        979 non-null    uint8         \n",
      " 51  Kentucky                      979 non-null    uint8         \n",
      " 52  Louisiana                     979 non-null    uint8         \n",
      " 53  Maine                         979 non-null    uint8         \n",
      " 54  Maryland                      979 non-null    uint8         \n",
      " 55  Massachusetts                 979 non-null    uint8         \n",
      " 56  Michigan                      979 non-null    uint8         \n",
      " 57  Minnesota                     979 non-null    uint8         \n",
      " 58  Mississippi                   979 non-null    uint8         \n",
      " 59  Missouri                      979 non-null    uint8         \n",
      " 60  Montana                       979 non-null    uint8         \n",
      " 61  Nebraska                      979 non-null    uint8         \n",
      " 62  Nevada                        979 non-null    uint8         \n",
      " 63  New Hampshire                 979 non-null    uint8         \n",
      " 64  New Jersey                    979 non-null    uint8         \n",
      " 65  New Mexico                    979 non-null    uint8         \n",
      " 66  New York                      979 non-null    uint8         \n",
      " 67  North Carolina                979 non-null    uint8         \n",
      " 68  North Dakota                  979 non-null    uint8         \n",
      " 69  Ohio                          979 non-null    uint8         \n",
      " 70  Oklahoma                      979 non-null    uint8         \n",
      " 71  Oregon                        979 non-null    uint8         \n",
      " 72  Pennsylvania                  979 non-null    uint8         \n",
      " 73  Puerto Rico                   979 non-null    uint8         \n",
      " 74  Rhode Island                  979 non-null    uint8         \n",
      " 75  South Carolina                979 non-null    uint8         \n",
      " 76  South Dakota                  979 non-null    uint8         \n",
      " 77  Tennessee                     979 non-null    uint8         \n",
      " 78  Texas                         979 non-null    uint8         \n",
      " 79  Utah                          979 non-null    uint8         \n",
      " 80  Vermont                       979 non-null    uint8         \n",
      " 81  Virginia                      979 non-null    uint8         \n",
      " 82  Washington                    979 non-null    uint8         \n",
      " 83  West Virginia                 979 non-null    uint8         \n",
      " 84  Wisconsin                     979 non-null    uint8         \n",
      " 85  Wyoming                       979 non-null    uint8         \n",
      " 86  earnings_pr_month             948 non-null    float64       \n",
      " 87  administrative & secretarial  979 non-null    int64         \n",
      " 88  business & finance            979 non-null    int64         \n",
      " 89  design & art                  979 non-null    int64         \n",
      " 90  education & training          979 non-null    int64         \n",
      " 91  engineering & architecture    979 non-null    int64         \n",
      " 92  legal                         979 non-null    int64         \n",
      " 93  programming & development     979 non-null    int64         \n",
      " 94  sales & marketing             979 non-null    int64         \n",
      " 95  writing & translation         979 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(18), object(21), uint8(50)\n",
      "memory usage: 407.3+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 21, 24, 26, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n"
     ]
    }
   ],
   "source": [
    "col_locs = [4,6,21,24,26,31,32,33,34]\n",
    "x = list(range(36,86))\n",
    "y = list(range(87,96))\n",
    "col_locs.extend(x)\n",
    "col_locs.extend(y)\n",
    "print(col_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 911 entries, 0 to 965\n",
      "Data columns (total 68 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   rating                        911 non-null    float64\n",
      " 1   hourly_rate                   911 non-null    int64  \n",
      " 2   has_rating                    911 non-null    object \n",
      " 3   months_active                 911 non-null    float64\n",
      " 4   num_skills                    911 non-null    int64  \n",
      " 5   bio_length                    911 non-null    int64  \n",
      " 6   bio_word_count                911 non-null    int64  \n",
      " 7   avg_word_length               911 non-null    float64\n",
      " 8   num_stop                      911 non-null    int64  \n",
      " 9   Alabama                       911 non-null    uint8  \n",
      " 10  Arizona                       911 non-null    uint8  \n",
      " 11  Arkansas                      911 non-null    uint8  \n",
      " 12  California                    911 non-null    uint8  \n",
      " 13  Colorado                      911 non-null    uint8  \n",
      " 14  Connecticut                   911 non-null    uint8  \n",
      " 15  Delaware                      911 non-null    uint8  \n",
      " 16  District of Columbia          911 non-null    uint8  \n",
      " 17  Florida                       911 non-null    uint8  \n",
      " 18  Georgia                       911 non-null    uint8  \n",
      " 19  Idaho                         911 non-null    uint8  \n",
      " 20  Illinois                      911 non-null    uint8  \n",
      " 21  Indiana                       911 non-null    uint8  \n",
      " 22  Iowa                          911 non-null    uint8  \n",
      " 23  Kansas                        911 non-null    uint8  \n",
      " 24  Kentucky                      911 non-null    uint8  \n",
      " 25  Louisiana                     911 non-null    uint8  \n",
      " 26  Maine                         911 non-null    uint8  \n",
      " 27  Maryland                      911 non-null    uint8  \n",
      " 28  Massachusetts                 911 non-null    uint8  \n",
      " 29  Michigan                      911 non-null    uint8  \n",
      " 30  Minnesota                     911 non-null    uint8  \n",
      " 31  Mississippi                   911 non-null    uint8  \n",
      " 32  Missouri                      911 non-null    uint8  \n",
      " 33  Montana                       911 non-null    uint8  \n",
      " 34  Nebraska                      911 non-null    uint8  \n",
      " 35  Nevada                        911 non-null    uint8  \n",
      " 36  New Hampshire                 911 non-null    uint8  \n",
      " 37  New Jersey                    911 non-null    uint8  \n",
      " 38  New Mexico                    911 non-null    uint8  \n",
      " 39  New York                      911 non-null    uint8  \n",
      " 40  North Carolina                911 non-null    uint8  \n",
      " 41  North Dakota                  911 non-null    uint8  \n",
      " 42  Ohio                          911 non-null    uint8  \n",
      " 43  Oklahoma                      911 non-null    uint8  \n",
      " 44  Oregon                        911 non-null    uint8  \n",
      " 45  Pennsylvania                  911 non-null    uint8  \n",
      " 46  Puerto Rico                   911 non-null    uint8  \n",
      " 47  Rhode Island                  911 non-null    uint8  \n",
      " 48  South Carolina                911 non-null    uint8  \n",
      " 49  South Dakota                  911 non-null    uint8  \n",
      " 50  Tennessee                     911 non-null    uint8  \n",
      " 51  Texas                         911 non-null    uint8  \n",
      " 52  Utah                          911 non-null    uint8  \n",
      " 53  Vermont                       911 non-null    uint8  \n",
      " 54  Virginia                      911 non-null    uint8  \n",
      " 55  Washington                    911 non-null    uint8  \n",
      " 56  West Virginia                 911 non-null    uint8  \n",
      " 57  Wisconsin                     911 non-null    uint8  \n",
      " 58  Wyoming                       911 non-null    uint8  \n",
      " 59  administrative & secretarial  911 non-null    int64  \n",
      " 60  business & finance            911 non-null    int64  \n",
      " 61  design & art                  911 non-null    int64  \n",
      " 62  education & training          911 non-null    int64  \n",
      " 63  engineering & architecture    911 non-null    int64  \n",
      " 64  legal                         911 non-null    int64  \n",
      " 65  programming & development     911 non-null    int64  \n",
      " 66  sales & marketing             911 non-null    int64  \n",
      " 67  writing & translation         911 non-null    int64  \n",
      "dtypes: float64(3), int64(14), object(1), uint8(50)\n",
      "memory usage: 179.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cleaning to just variables that will be used in the model\n",
    "analysis_dt = dt.iloc[:,col_locs]\n",
    "analysis_dt = analysis_dt.dropna()  # Removing people with NA\n",
    "analysis_dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database and save data to it\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s' %\n",
    "                       (username, pswd, dbname))\n",
    "analysis_dt.to_sql(\"analysis_table\", engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD: Working on clustering the skills\n",
    "\n",
    "1. This didn't work. I think the reason is because I don't have enough skills for each user. Therefore, it can't find enough similarity between them. Maybe I could go back and jump into each users url and scrape their entire skills list? Time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found K-Modes on stackoverflow\n",
    "# Following the package documentation\n",
    "# Ref: https://pypi.org/project/kmodes/\n",
    "# Ref: https://stackoverflow.com/questions/42639824/python-k-modes-explanation\n",
    "# Ref: https://www.kaggle.com/ashydv/bank-customer-clustering-k-modes-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning column names from the dummies database\n",
    "skills_table_dummies.columns = skills_table_dummies.columns.str.strip().str.lower().str.replace(\n",
    "    ' ', '_').str.replace('(', '').str.replace(')', '').str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_table_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling with K Modes\n",
    "cost = []\n",
    "for num_clusters in list(range(20, 30)):\n",
    "    kmode = KModes(n_clusters=num_clusters, init=\"Huang\", verbose=0)\n",
    "    kmode.fit_predict(skills_table_dummies)\n",
    "    cost.append(kmode.cost_)\n",
    "    print(\"Finished Cluster: \" + str(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i for i in range(20, 30, 1)])\n",
    "plt.plot(y, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmode = KModes(n_clusters=28, init='Huang', verbose=0)\n",
    "clusters = kmode.fit_predict(skills_table_dummies)\n",
    "\n",
    "kmodes = kmode.cluster_centroids_\n",
    "shape = kmodes.shape\n",
    "\n",
    "for i in range(shape[0]):\n",
    "    if sum(kmodes[i, :]) == 0:\n",
    "        print(\"\\ncluster \" + str(i) + \": \")\n",
    "        print(\"no-skills cluster\")\n",
    "    else:\n",
    "        print(\"\\ncluster \" + str(i) + \": \")\n",
    "        cent = kmodes[i, :]\n",
    "        for j in skills_table_dummies.columns[np.nonzero(cent)]:\n",
    "            print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_assigned = km.predict(skills_table_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(clust_assigned, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cluster_crosswalk = pd.DataFrame(\n",
    "    skills_table['profile_url'].unique(), columns=[\"profile_url\"]).sort_values(by=\"profile_url\")\n",
    "user_cluster_crosswalk['cluster'] = clust_assigned\n",
    "user_cluster_crosswalk[user_cluster_crosswalk['cluster'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging into the skills table to investigate those with \"no skills\"\n",
    "tmp = pd.merge(skills_table, user_cluster_crosswalk, on=\"profile_url\")\n",
    "tmp[tmp['cluster'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems to not be working great.\n",
    "# Why is it putting so many people into the no skills cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for the Probability of Getting a Job (0/1)\n",
    "\n",
    "### Outcome: Probability of getting a job  . . . ever?\n",
    "\n",
    "1. Need to clean all of this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the (obvious) relationship between memebershp time and # of jobs completed\n",
    "# How strong is the relationship?\n",
    "# First have to clean the invoices paid variable\n",
    "dt.invoices_paid = dt.invoices_paid.str.replace(',', '')\n",
    "dt.invoices_paid = pd.to_numeric(dt.invoices_paid)\n",
    "dt.invoices_paid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who is NA? I have a whole bunch of 1s but then some NAs?\n",
    "# The question for a poisson model is: did they just have no invoices OR\n",
    "# were they never going to have any invoices.\n",
    "# Looked at some of them and I'll treat them as zeros. So there are really that many ones?!?\n",
    "dt[dt.invoices_paid.isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning zero to the NAs. This is important!!\n",
    "dt.loc[dt.invoices_paid.isna(), 'invoices_paid'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dt.invoices_paid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow, very heavy on the zeros. Let's look closer.\n",
    "dt.invoices_paid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ah, so it is truncating at one.\n",
    "# This is going to be problematic for those who are actually at a value of one.\n",
    "# I can either rerun the scrape and create something to make the val = 0\n",
    "# or I can just move forward. . .\n",
    "\n",
    "# For now I'm going to keep moving forward and treat 1 as 0.\n",
    "# Note, it is more likely than not that they are = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dist vs months active (no 1s)\n",
    "sns.scatterplot(x='months_active', y='invoices_paid',\n",
    "                data=dt[dt.invoices_paid > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few massive outliers. Going to rough chop it down and replot\n",
    "invoice_gtr_one = dt.invoices_paid > 1\n",
    "invoice_ls_2000 = dt.invoices_paid < 2000\n",
    "sns.scatterplot(x='months_active', y='invoices_paid',\n",
    "                data=dt[invoice_gtr_one & invoice_ls_2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm, there may be a slight signal but you would expect a stronger trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dist vs years active (no 1s)\n",
    "sns.scatterplot(x='years_active', y='invoices_paid',\n",
    "                data=dt[invoice_gtr_one & invoice_ls_2000])\n",
    "# Slight postive non-linear trend bu there is a HUGE outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoices Paid - Notes\n",
    "\n",
    "It has a weak-ish relationship with time. There are a lot of really heavy users of the platform that dominate the market. Let's zoom into the first year and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at invoices pad in the first few months (among those only active for a shorter period of time)\n",
    "sns.scatterplot(x='months_active',\n",
    "                y='invoices_paid',\n",
    "                data=dt[dt['years_active'] < 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating invoices / time active\n",
    "dt['invoices_per_month'] = dt['invoices_paid'] / \\\n",
    "    dt['months_active']\n",
    "sns.distplot(dt.invoices_per_month)\n",
    "print(dt.invoices_per_month.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded on zero with a long tail. Continues to sell that there are some serious power users.\n",
    "# Average invoice per month is equal to one, but I left in the 1s that could be zeros. . .\n",
    "# Real average is likely near zero.\n",
    "\n",
    "# The question now is: Does this mean differ by any characteristic that I observe in the data?\n",
    "# For people with a different skill set (Andriod) do they have a higher mean invoice/month rate?\n",
    "# For people in different regions do they have a higher mean invoice/month rate?\n",
    "# For people with lower hourly rates do they have a higher mean invoice/month rate??\n",
    "\n",
    "# The next important step is to figure out how to use the skills data.\n",
    "# It would be great to try and create clusters of the skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
