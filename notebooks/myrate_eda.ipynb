{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Freelance Profiles with relation to Hourly Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes to self:\n",
    "\n",
    "# The clustering on skills didn't work because there isn't enough skills per user.\n",
    "# Almost all users have about 5 skills, but there isn't enough overlap between them.\n",
    "# Futhermore, there is just about no signal relating the features to hourly rate.\n",
    "# Need to pivot and think of some alternative way to use this data.\n",
    "# Also, I need to figure out why everyone has a \"1\" for their invoices paid.\n",
    "\n",
    "# Do a regression tree model\n",
    "# Deriving other features from the text\n",
    "# Sentiment: Passive vs active voice?\n",
    "# do the skills appear in the text \n",
    "# Try a targeted search and get numerics out\n",
    "    # remove +'s' or try regex \n",
    "# Use text to look for those skills and maybe try to find words around it?\n",
    "# Skills in text vs not in the skill list \n",
    "# Naively do some kind of embedding (word2vec)\n",
    "    # Toss in their description and it creates a vector representation \n",
    "    # And then try looking at clusters in that space\n",
    "    # Specify the length of the vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Merging to get EDA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Packages for PostgreSQL Import and Export\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# Packages for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "\n",
    "# Packages for K-Modes Cluster\n",
    "import numpy as np\n",
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ideally I'll move this into the project config.py file\n",
    "# Otherwise for now I have to just manually assign . . .\n",
    "\n",
    "dbname = \"freelance_db\"\n",
    "username = \"Metaverse\"\n",
    "pswd = \"Arcifice91\"\n",
    "\n",
    "# Connect to Data\n",
    "con = None\n",
    "con = psycopg2.connect(database=dbname, user=username,\n",
    "                       host='localhost', password=pswd)\n",
    "\n",
    "# Checking shapes of tables\n",
    "sql_query = \"\"\"SELECT * from user_details_table;\"\"\"\n",
    "dtls_table = pd.read_sql_query(sql_query, con)\n",
    "\n",
    "sql_query = \"\"\"SELECT * from freelance_table;\"\"\"\n",
    "fl_table = pd.read_sql_query(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merging\n",
    "# Modifying profile_url in the details table so I can merge it with the fl_table\n",
    "dtls_table['profile_url'] = \"https://www.guru.com\"+dtls_table['profile_url']\n",
    "\n",
    "# Now I'm merging them together to make dt\n",
    "dt = pd.merge(fl_table, dtls_table, on='profile_url')\n",
    "dt.shape\n",
    "dt = dt.drop(columns=(['index_x']))\n",
    "dt = dt.drop_duplicates(subset='profile_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merging in data to crosswalk states with region labels\n",
    "state_region_crswlk = pd.read_csv(\n",
    "    '~/Desktop/Insight/projects/myrate/data/raw/census-regions/us census bureau regions and divisions.csv')\n",
    "state_region_crswlk.head()\n",
    "\n",
    "dt = pd.merge(dt, state_region_crswlk,\n",
    "              how='left', left_on='state', right_on='State')\n",
    "\n",
    "# Fixing region value for individuals living in Puerto Rico\n",
    "dt.loc[dt['state'] == \"Puerto Rico\", 'Region'] = \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Outcome: Hourly Rate\n",
    "### Beginning with investigating the geographic labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean hourly rate ($): 31.94\n"
     ]
    }
   ],
   "source": [
    "# What is the overall mean?\n",
    "print(\"Mean hourly rate ($):\", round(dt['hourly_rate'].mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean by region?\n",
    "dt.groupby(['Region']).hourly_rate.mean()\n",
    "\n",
    "# There is some variation, but it is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean across states?\n",
    "dt.groupby(['state']).hourly_rate.mean().sort_values().describe()\n",
    "\n",
    "# Pretty decent spread. This may be the most powerful signal yet.\n",
    "# If you print out hte full table it is clear that there is variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the variation within states?\n",
    "state_lvl_hourly_rate_descriptives = {}\n",
    "state_lvl_hourly_rate_descriptives['min'] = dt.groupby(\n",
    "    ['state']).hourly_rate.min()\n",
    "state_lvl_hourly_rate_descriptives['mean'] = dt.groupby(\n",
    "    ['state']).hourly_rate.mean()\n",
    "state_lvl_hourly_rate_descriptives['max'] = dt.groupby(\n",
    "    ['state']).hourly_rate.max()\n",
    "state_lvl_hourly_rate_descriptives['var'] = dt.groupby(\n",
    "    ['state']).hourly_rate.var()\n",
    "dt_state_hr = pd.DataFrame(state_lvl_hourly_rate_descriptives)\n",
    "\n",
    "# A decent amount of variation within the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I tried to break it down further to the city level\n",
    "# But the city data is really messy and not worth the time sink\n",
    "# To try and get it set up. The idea would be to merge on\n",
    "# rural vs urban and see if it can help me filter out a signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the relationship between a users \"rating\" and the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaing it up real quick\n",
    "dt.rating = dt.rating.str.replace('%', '')\n",
    "dt.rating = dt.rating.str.replace('NA', '')\n",
    "dt.rating = pd.to_numeric(dt.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with Missing Values\n",
    "print(\"Number of missing values: \", dt.rating.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the spread look like for the rest?\n",
    "dt.rating.describe()\n",
    "\n",
    "# Basically no variation. Okay, let's make a binary variable (has_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \"has_rating\"\n",
    "dt['has_rating'] = None\n",
    "dt.loc[dt['rating'].isna(), 'has_rating'] = 0\n",
    "dt.loc[dt['rating'] > 0, 'has_rating'] = 1\n",
    "\n",
    "# Comparing outcome means by has_rating\n",
    "dt.groupby(['has_rating']).hourly_rate.mean()\n",
    "\n",
    "# Small difference, nothing substantial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the duration of membership and hourly rate\n",
    "\n",
    "1. Convert member start date to a date object\n",
    "2. Calculate years / months they've been a member (to today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_convert(member_since):\n",
    "    try:\n",
    "        tmp = datetime.strptime(member_since, '%b, %Y')\n",
    "        #tmp = tmp.strftime('%Y-%m')\n",
    "    except:\n",
    "        tmp = 'NaN'\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_active(date):\n",
    "    cur_year = datetime.now().year\n",
    "    try:\n",
    "        yrs_active = cur_year - date.year\n",
    "    except:\n",
    "        yrs_active = 'NaN'\n",
    "\n",
    "    return yrs_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_active(date):\n",
    "    cur_year = datetime.now().year\n",
    "    cur_month = datetime.now().month\n",
    "\n",
    "    try:\n",
    "        mnths_active = (cur_year - date.year)*12 + (cur_month - date.month)\n",
    "    except:\n",
    "        mnths_active = 'NaN'\n",
    "\n",
    "    return mnths_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting member_since to date\n",
    "dt.member_since = dt.member_since.str.strip()\n",
    "dt['start_date'] = dt.member_since.apply(date_convert)\n",
    "dt['years_active'] = dt.start_date.apply(years_active)\n",
    "dt['months_active'] = dt.start_date.apply(months_active)\n",
    "\n",
    "# Therea are 31 NAs. Just going to ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What I want to understand is:\n",
    "# How does the hourly rate (average) change across years active?\n",
    "dt.groupby('years_active').hourly_rate.mean()\n",
    "\n",
    "# Nothing much. It ramps up if years active > 17. Building that binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['active_17up'] = (dt['years_active'] >= 17) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay let's try looking at months active. Maybe on a finer scale there is some difference?\n",
    "x = dt.groupby('months_active').hourly_rate.mean().index\n",
    "y = dt.groupby('months_active').hourly_rate.mean()\n",
    "ax = sns.scatterplot(x=x, y=y,\n",
    "                     color='black')\n",
    "ax.set(xlabel='months_active', ylabel='Average hourly_rate')\n",
    "plt.show()\n",
    "\n",
    "# No real pattern emerges. Unfortunately not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring hourly rate and how it relates to the skills\n",
    "\n",
    "1. Obtain the dataset that is long by skills and shrink it down to just the skills. I'll work with that for this.\n",
    "2. Create some quick features such as: # of skills and top skill. These are user level so I can attach them back to dt to have everything in one place.\n",
    "\n",
    "Note: the skills are standardized on guru which makes this more straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_query = \"\"\"SELECT profile_url, skills_list from freelance_table;\"\"\"\n",
    "skills_table = pd.read_sql_query(sql_query, con)\n",
    "skills_table_dummies = pd.get_dummies(skills_table, columns=[\n",
    "                                      'skills_list'], prefix='').groupby(['profile_url']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of skills\n",
    "num_skills = skills_table.groupby('profile_url').count()\n",
    "num_skills = num_skills.rename(columns={\"skills_list\": \"num_skills\"})\n",
    "num_skills = num_skills.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging num skills into dt\n",
    "dt = pd.merge(dt, num_skills, on=\"profile_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.groupby('num_skills').hourly_rate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems that for those with less than five skills listed\n",
    "# they tend to have a lower hourly rate.\n",
    "dt['less_five_skills'] = (dt['num_skills'] < 5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving on to something else. Let's look at the top skills (first skill listed)\n",
    "first_skill = skills_table[skills_table.groupby(\n",
    "    'profile_url')['skills_list'].cumcount() == 0]\n",
    "\n",
    "first_skill = first_skill.rename(\n",
    "    columns={\"profile_url\": \"profile_url\", \"skills_list\": \"first_skill\"})\n",
    "\n",
    "dt = pd.merge(dt, first_skill, on=\"profile_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring First Skills\n",
    "print(\"Number of unique skills: \", dt.first_skill.nunique())\n",
    "dt.groupby('first_skill').first_skill.count().describe()\n",
    "\n",
    "# There is some repition but not much. Maybe I can get something off the extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring extreme first skill frequencies\n",
    "skill_freq = {}\n",
    "skill_freq['skill_frequency'] = dt.groupby(\n",
    "    'first_skill').first_skill.count().sort_values(ascending=False)\n",
    "skill_freq['skills_list'] = dt.groupby(\n",
    "    'first_skill').first_skill.count().sort_values(ascending=False).index\n",
    "skill_freq = pd.DataFrame(skill_freq)\n",
    "skill_freq = skill_freq.reset_index()\n",
    "skill_freq = skill_freq.drop(['first_skill'], axis=1)\n",
    "\n",
    "dt = pd.merge(dt, skill_freq, on=\"skills_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='skill_frequency', y='hourly_rate', data=dt)\n",
    "\n",
    "# Nope, not much of anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just have to try to keep thinking of ways I could use this information.\n",
    "# Ideally, I would be able to go group them by category and calculate hourly rate on that\n",
    "# There may also be an interaction effect occuring between the category and something like\n",
    "# years of experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the process of using the \"bio\" data\n",
    "\n",
    "1. The easiest variable to create is the len(bio)\n",
    "2. I'll have to try and expand it more using some other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bio(bio):\n",
    "    try:\n",
    "        cleaned_bio = ''.join(s for s in bio if ord(s) > 31 and ord(s) < 126)\n",
    "    except:\n",
    "        cleaned_bio = \"NaN\"\n",
    "    return cleaned_bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_bio(bio):\n",
    "    if bio == \"NaN\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average word length in bio\n",
    "def avg_word_ln(bio):\n",
    "    try:\n",
    "        words = bio.split()\n",
    "        res = (sum(len(word) for word in words)/len(words))\n",
    "    except:\n",
    "        res = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stop words\n",
    "def num_stopwords(bio):\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    try:\n",
    "        res = len([x for x in bio.split() if x in stop])\n",
    "    except:\n",
    "        res = -1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['bio_clean'] = dt.bio.apply(clean_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['bio_length'] = dt.bio_clean.apply(len_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of separate words in bio\n",
    "dt['bio_word_count'] = dt['bio_clean'].apply(\n",
    "    lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['avg_word_length'] = dt['bio_clean'].apply(avg_word_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['num_stop'] = dt['bio_clean'].apply(num_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing before pulling more features\n",
    "\n",
    "# Remvoing stop words\n",
    "stop = stopwords.words('english')\n",
    "dt['bio_processed'] = dt['bio_clean'].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# Removing punctuation\n",
    "dt['bio_processed'] = dt['bio_processed'].str.replace(\n",
    "    '[^\\w\\s]', '')\n",
    "\n",
    "# Lower Case\n",
    "dt['bio_processed'] = dt['bio_processed'].apply(\n",
    "    lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring how these bio features related to hourly rate\n",
    "\n",
    "# Starting with the length of a users bio\n",
    "sns.scatterplot(x='bio_length', y='hourly_rate', data=dt)\n",
    "\n",
    "# Nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about how the word count related to hourly rate?\n",
    "sns.scatterplot(x='bio_word_count', y='hourly_rate', data=dt)\n",
    "\n",
    "# Nope, again nothing of interest here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, what about how word length\n",
    "sns.scatterplot(x='hourly_rate', y='avg_word_length', data=dt)\n",
    "\n",
    "# Hmm, no. But there are some very unusual outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lastly, the number of stop words\n",
    "sns.scatterplot(x='num_stop', y='hourly_rate', data=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole lot of nothing came out of the bio features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing number of employers and hourly rate\n",
    "\n",
    "Nevermind. There is no variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making State dummy variables\n",
    "state_dummies = pd.get_dummies(dt['state'])\n",
    "dt = pd.concat([dt, state_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earnings per Month\n",
    "dt['earnings_ever'] = dt['earnings_ever'].str.replace('$', '')\n",
    "dt['earnings_ever'] = dt['earnings_ever'].str.replace(',', '')\n",
    "dt['earnings_ever'] = pd.to_numeric(dt['earnings_ever'])\n",
    "dt['earnings_pr_month'] = dt['earnings_ever'] / \\\n",
    "    dt['months_active']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving out Modified Dataset\n",
    "\n",
    "1. First printing the columns I have for reference.\n",
    "2. Saving it to a new table in the postgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_locs = [6,21,23,25,27,29]\n",
    "x = list(range(36,86))\n",
    "col_locs.extend(x)\n",
    "print(col_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleaning to just variables that will be used in the model\n",
    "analysis_dt = dt.iloc[:,col_locs]\n",
    "analysis_dt = analysis_dt.dropna()  # Removing people with NA\n",
    "analysis_dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database and save data to it\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s' %\n",
    "                       (username, pswd, dbname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dt.to_sql(\"analysis_table\", engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Skills and Labels\n",
    "\n",
    "### Goal: Merge scraped skills list and categories into data based on user reported skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"SELECT * from skills_categories_table;\"\"\"\n",
    "sk_table = pd.read_sql_query(sql_query, con)\n",
    "sk_table = sk_table.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Programming &amp; Development (1,456)</td>\n",
       "      <td>Web Development &amp; Design (558)</td>\n",
       "      <td>Web Development (325)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Programming &amp; Development (1,456)</td>\n",
       "      <td>Web Development &amp; Design (558)</td>\n",
       "      <td>Front End Development (257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programming &amp; Development (1,456)</td>\n",
       "      <td>Web Development &amp; Design (558)</td>\n",
       "      <td>Back End Development (238)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Programming &amp; Development (1,456)</td>\n",
       "      <td>Web Development &amp; Design (558)</td>\n",
       "      <td>PHP (146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Programming &amp; Development (1,456)</td>\n",
       "      <td>Web Development &amp; Design (558)</td>\n",
       "      <td>User Experience Design (94)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Category                     Subcategory  \\\n",
       "0  Programming & Development (1,456)  Web Development & Design (558)   \n",
       "1  Programming & Development (1,456)  Web Development & Design (558)   \n",
       "2  Programming & Development (1,456)  Web Development & Design (558)   \n",
       "3  Programming & Development (1,456)  Web Development & Design (558)   \n",
       "4  Programming & Development (1,456)  Web Development & Design (558)   \n",
       "\n",
       "                        Skills  \n",
       "0        Web Development (325)  \n",
       "1  Front End Development (257)  \n",
       "2   Back End Development (238)  \n",
       "3                    PHP (146)  \n",
       "4  User Experience Design (94)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sk_table.shape)\n",
    "sk_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Numbers\n",
    "sk_table['Skill_Frequency'] = pd.to_numeric(sk_table.Skills.str.extract(\n",
    "    r'\\((\\d*?)\\)').iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Columns of frequency labels\n",
    "sk_table['Skills_Clean'] = sk_table.Skills.str.replace(\n",
    "    r'\\((\\d*?)\\)','').str.strip().str.lower()\n",
    "sk_table['Category'] = sk_table.Category.str.replace(\n",
    "    r'\\((.*?)\\)','').str.strip().str.lower()\n",
    "sk_table['Subcategory'] = sk_table.Subcategory.str.replace(\n",
    "    r'\\((\\d*?)\\)','').str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Skill_Frequency</th>\n",
       "      <th>Skills_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming &amp; development</td>\n",
       "      <td>web development &amp; design</td>\n",
       "      <td>Web Development (325)</td>\n",
       "      <td>325.0</td>\n",
       "      <td>web development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programming &amp; development</td>\n",
       "      <td>web development &amp; design</td>\n",
       "      <td>Front End Development (257)</td>\n",
       "      <td>257.0</td>\n",
       "      <td>front end development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>programming &amp; development</td>\n",
       "      <td>web development &amp; design</td>\n",
       "      <td>Back End Development (238)</td>\n",
       "      <td>238.0</td>\n",
       "      <td>back end development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>programming &amp; development</td>\n",
       "      <td>apps &amp; mobile</td>\n",
       "      <td>App &amp; Mobile Programming (164)</td>\n",
       "      <td>164.0</td>\n",
       "      <td>app &amp; mobile programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>programming &amp; development</td>\n",
       "      <td>web development &amp; design</td>\n",
       "      <td>PHP (146)</td>\n",
       "      <td>146.0</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Category               Subcategory  \\\n",
       "0   programming & development  web development & design   \n",
       "1   programming & development  web development & design   \n",
       "2   programming & development  web development & design   \n",
       "20  programming & development             apps & mobile   \n",
       "3   programming & development  web development & design   \n",
       "\n",
       "                            Skills  Skill_Frequency              Skills_Clean  \n",
       "0            Web Development (325)            325.0           web development  \n",
       "1      Front End Development (257)            257.0     front end development  \n",
       "2       Back End Development (238)            238.0      back end development  \n",
       "20  App & Mobile Programming (164)            164.0  app & mobile programming  \n",
       "3                        PHP (146)            146.0                       php  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_table.sort_values(['Skill_Frequency'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in the user skills table\n",
    "sql_query = \"\"\"SELECT profile_url, skills_list from freelance_table;\"\"\"\n",
    "skills_table = pd.read_sql_query(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4539, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_table['skills_list'] = skills_table['skills_list'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.merge(skills_table,sk_table,\n",
    "               left_on='skills_list',right_on='Skills_Clean', how=\"left\",\n",
    "               indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to try and see how many people match\n",
    "# If they matched on at least one thing I can then expand that onto the rest of their data\n",
    "tmp['matched'] = (tmp['_merge'] == \"both\") * 1\n",
    "number_of_matches_by_user = tmp.groupby(['profile_url']).matched.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(number_of_matches_by_user == 0).sum()\n",
    "\n",
    "# This is great, a good chunk of people matched.\n",
    "# Now I can guess what field they were in (for the ones who matched)\n",
    "# and then label the people similar to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['num_matched'] = tmp.groupby(['profile_url']).matched.transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So for people who matched, I want to determine which category most common for them\n",
    "test = tmp[tmp['num_matched'] > 0][['profile_url','Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>administrative &amp; secretarial</th>\n",
       "      <th>business &amp; finance</th>\n",
       "      <th>design &amp; art</th>\n",
       "      <th>education &amp; training</th>\n",
       "      <th>engineering &amp; architecture</th>\n",
       "      <th>legal</th>\n",
       "      <th>programming &amp; development</th>\n",
       "      <th>sales &amp; marketing</th>\n",
       "      <th>writing &amp; translation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/35-year-editor-has-your-back</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/86-keys-communications</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/a-stringham</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/a-wordsmith</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.guru.com/freelancers/aa-consultants</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category                                            administrative & secretarial  \\\n",
       "profile_url                                                                        \n",
       "https://www.guru.com/freelancers/35-year-editor...                             0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                             0   \n",
       "https://www.guru.com/freelancers/a-stringham                                   2   \n",
       "https://www.guru.com/freelancers/a-wordsmith                                   0   \n",
       "https://www.guru.com/freelancers/aa-consultants                                0   \n",
       "\n",
       "Category                                            business & finance  \\\n",
       "profile_url                                                              \n",
       "https://www.guru.com/freelancers/35-year-editor...                   0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                   0   \n",
       "https://www.guru.com/freelancers/a-stringham                         0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                         0   \n",
       "https://www.guru.com/freelancers/aa-consultants                      1   \n",
       "\n",
       "Category                                            design & art  \\\n",
       "profile_url                                                        \n",
       "https://www.guru.com/freelancers/35-year-editor...             0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...             0   \n",
       "https://www.guru.com/freelancers/a-stringham                   0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                   0   \n",
       "https://www.guru.com/freelancers/aa-consultants                0   \n",
       "\n",
       "Category                                            education & training  \\\n",
       "profile_url                                                                \n",
       "https://www.guru.com/freelancers/35-year-editor...                     0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                     0   \n",
       "https://www.guru.com/freelancers/a-stringham                           0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                           0   \n",
       "https://www.guru.com/freelancers/aa-consultants                        0   \n",
       "\n",
       "Category                                            engineering & architecture  \\\n",
       "profile_url                                                                      \n",
       "https://www.guru.com/freelancers/35-year-editor...                           0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                           0   \n",
       "https://www.guru.com/freelancers/a-stringham                                 0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                                 0   \n",
       "https://www.guru.com/freelancers/aa-consultants                              0   \n",
       "\n",
       "Category                                            legal  \\\n",
       "profile_url                                                 \n",
       "https://www.guru.com/freelancers/35-year-editor...      0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...      0   \n",
       "https://www.guru.com/freelancers/a-stringham            0   \n",
       "https://www.guru.com/freelancers/a-wordsmith            0   \n",
       "https://www.guru.com/freelancers/aa-consultants         0   \n",
       "\n",
       "Category                                            programming & development  \\\n",
       "profile_url                                                                     \n",
       "https://www.guru.com/freelancers/35-year-editor...                          0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                          0   \n",
       "https://www.guru.com/freelancers/a-stringham                                0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                                0   \n",
       "https://www.guru.com/freelancers/aa-consultants                             2   \n",
       "\n",
       "Category                                            sales & marketing  \\\n",
       "profile_url                                                             \n",
       "https://www.guru.com/freelancers/35-year-editor...                  0   \n",
       "https://www.guru.com/freelancers/86-keys-commun...                  0   \n",
       "https://www.guru.com/freelancers/a-stringham                        0   \n",
       "https://www.guru.com/freelancers/a-wordsmith                        0   \n",
       "https://www.guru.com/freelancers/aa-consultants                     0   \n",
       "\n",
       "Category                                            writing & translation  \n",
       "profile_url                                                                \n",
       "https://www.guru.com/freelancers/35-year-editor...                      5  \n",
       "https://www.guru.com/freelancers/86-keys-commun...                      2  \n",
       "https://www.guru.com/freelancers/a-stringham                            1  \n",
       "https://www.guru.com/freelancers/a-wordsmith                            2  \n",
       "https://www.guru.com/freelancers/aa-consultants                         0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping wide\n",
    "# test['counter'] = test.groupby(['profile_url']).cumcount()+1\n",
    "test['counter'] = 1\n",
    "skill_category_matrix = test.pivot_table(index = 'profile_url', columns = 'Category', \n",
    "                     values = 'counter', aggfunc = 'sum', \n",
    "                     fill_value = 0)\n",
    "skill_category_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(711, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_category_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Update: Working with Skill Categories\n",
    "\n",
    "1. I now have a user-level matrix with the skill categories along the top\n",
    "2. I also have a user-level matrix with skill categories along the top but with missing data.\n",
    "3. I want to impute that matrix. How?\n",
    "4. The simplest way would be to create the **very** wide skill matrix and do lookups for similarity.\n",
    "    - For example, take skills vector (long, 0/1s) of user A who I want to impute his categories. Find the most similar vector among the users with data. Impute from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First resetting index on skill_category_matrix\n",
    "skill_category_matrix = skill_category_matrix.reset_index()\n",
    "skill_category_matrix['has_categories'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And creating skills dummy matrix\n",
    "sql_query = \"\"\"SELECT profile_url, skills_list from freelance_table;\"\"\"\n",
    "skills_table = pd.read_sql_query(sql_query, con)\n",
    "skills_table_dummies = pd.get_dummies(skills_table, columns=[\n",
    "                                      'skills_list'], prefix='').groupby(['profile_url']).sum()\n",
    "skills_table_dummies = skills_table_dummies.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And merging\n",
    "skills_table_dummies = pd.merge(skills_table_dummies, \n",
    "                                skill_category_matrix[['profile_url','has_categories']], \n",
    "                                left_on = 'profile_url',\n",
    "                                right_on = 'profile_url',\n",
    "                                how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the NA has_categories so it's a useful indicator\n",
    "skills_table_dummies['has_categories'] = skills_table_dummies['has_categories'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cat = skills_table_dummies[skills_table_dummies['has_categories'] == 1]\n",
    "no_cat = skills_table_dummies[skills_table_dummies['has_categories'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_distance():\n",
    "    sqrdist = np.sum(np.sqrt(np.square(user_no_cat-user_has_cat)))\n",
    "    return sqrdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one long list of all distances\n",
    "dist = []\n",
    "for k in range(0,no_cat.shape[0]):\n",
    "    for j in range(0,has_cat.shape[0]):\n",
    "        user_no_cat = np.array(list(no_cat.iloc[k,1:]))\n",
    "        user_has_cat = np.array(list(has_cat.iloc[j,1:]))\n",
    "        dist.append(raw_distance())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting that list into a numpy matrix of the appropriate shape\n",
    "res = np.array(dist).reshape(no_cat.shape[0],has_cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding where the FIRST minimum is for each user\n",
    "# Come back later and clean this up to return multiple minimums\n",
    "# Making my life easy for now . . .\n",
    "min_indices = np.argmin(res, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to take the minimum index and use it on the has_cat table\n",
    "# to look up the person with whom they have similar relationship.\n",
    "# I can then extract this users row and slap it into a new table (impute_cat)\n",
    "cols = list(skill_category_matrix.columns)[0:10]\n",
    "impute_cat = pd.DataFrame(columns=cols)\n",
    "\n",
    "impute_cat['profile_url'] = no_cat['profile_url']\n",
    "\n",
    "for j in range(0,no_cat.shape[0]):\n",
    "    impute_cat.iloc[j,1:] = skill_category_matrix.iloc[min_indices[j],1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to skill_category_matrix\n",
    "full_cat = skill_category_matrix.append(impute_cat).drop(['has_categories'], axis = 1)\n",
    "\n",
    "# Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill Categories Update #2\n",
    "\n",
    "1. I imputed the skill categories using the L2 norm to find similar users\n",
    "2. Now I have a user level matrix with the skill category and the number of skills they have in it.\n",
    "3. However, the number is a little misleading because sometimes they just didn't match on their other listed skills.\n",
    "4. Therefore, I now have the question of:\n",
    "    - Do I create dummies for whether or not they have a certain category, at all?\n",
    "    - Or do I pick the one they have the largest value in?\n",
    "    - I think I may just do dummies for now. This means I just need to make any value > 0 = 1\n",
    "5. Anyways, the next step is to explore the mean hourly_rate by skill categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies on the full_cat\n",
    "full_cat.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD: Working on clustering the skills\n",
    "\n",
    "1. This didn't work. I think the reason is because I don't have enough skills for each user. Therefore, it can't find enough similarity between them. Maybe I could go back and jump into each users url and scrape their entire skills list? Time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found K-Modes on stackoverflow\n",
    "# Following the package documentation\n",
    "# Ref: https://pypi.org/project/kmodes/\n",
    "# Ref: https://stackoverflow.com/questions/42639824/python-k-modes-explanation\n",
    "# Ref: https://www.kaggle.com/ashydv/bank-customer-clustering-k-modes-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning column names from the dummies database\n",
    "skills_table_dummies.columns = skills_table_dummies.columns.str.strip().str.lower().str.replace(\n",
    "    ' ', '_').str.replace('(', '').str.replace(')', '').str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_table_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling with K Modes\n",
    "cost = []\n",
    "for num_clusters in list(range(20, 30)):\n",
    "    kmode = KModes(n_clusters=num_clusters, init=\"Huang\", verbose=0)\n",
    "    kmode.fit_predict(skills_table_dummies)\n",
    "    cost.append(kmode.cost_)\n",
    "    print(\"Finished Cluster: \" + str(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i for i in range(20, 30, 1)])\n",
    "plt.plot(y, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmode = KModes(n_clusters=28, init='Huang', verbose=0)\n",
    "clusters = kmode.fit_predict(skills_table_dummies)\n",
    "\n",
    "kmodes = kmode.cluster_centroids_\n",
    "shape = kmodes.shape\n",
    "\n",
    "for i in range(shape[0]):\n",
    "    if sum(kmodes[i, :]) == 0:\n",
    "        print(\"\\ncluster \" + str(i) + \": \")\n",
    "        print(\"no-skills cluster\")\n",
    "    else:\n",
    "        print(\"\\ncluster \" + str(i) + \": \")\n",
    "        cent = kmodes[i, :]\n",
    "        for j in skills_table_dummies.columns[np.nonzero(cent)]:\n",
    "            print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_assigned = km.predict(skills_table_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(clust_assigned, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cluster_crosswalk = pd.DataFrame(\n",
    "    skills_table['profile_url'].unique(), columns=[\"profile_url\"]).sort_values(by=\"profile_url\")\n",
    "user_cluster_crosswalk['cluster'] = clust_assigned\n",
    "user_cluster_crosswalk[user_cluster_crosswalk['cluster'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging into the skills table to investigate those with \"no skills\"\n",
    "tmp = pd.merge(skills_table, user_cluster_crosswalk, on=\"profile_url\")\n",
    "tmp[tmp['cluster'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems to not be working great.\n",
    "# Why is it putting so many people into the no skills cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for the Probability of Getting a Job (0/1)\n",
    "\n",
    "### Outcome: Probability of getting a job  . . . ever?\n",
    "\n",
    "1. Need to clean all of this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the (obvious) relationship between memebershp time and # of jobs completed\n",
    "# How strong is the relationship?\n",
    "# First have to clean the invoices paid variable\n",
    "dt.invoices_paid = dt.invoices_paid.str.replace(',', '')\n",
    "dt.invoices_paid = pd.to_numeric(dt.invoices_paid)\n",
    "dt.invoices_paid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who is NA? I have a whole bunch of 1s but then some NAs?\n",
    "# The question for a poisson model is: did they just have no invoices OR\n",
    "# were they never going to have any invoices.\n",
    "# Looked at some of them and I'll treat them as zeros. So there are really that many ones?!?\n",
    "dt[dt.invoices_paid.isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning zero to the NAs. This is important!!\n",
    "dt.loc[dt.invoices_paid.isna(), 'invoices_paid'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dt.invoices_paid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow, very heavy on the zeros. Let's look closer.\n",
    "dt.invoices_paid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ah, so it is truncating at one.\n",
    "# This is going to be problematic for those who are actually at a value of one.\n",
    "# I can either rerun the scrape and create something to make the val = 0\n",
    "# or I can just move forward. . .\n",
    "\n",
    "# For now I'm going to keep moving forward and treat 1 as 0.\n",
    "# Note, it is more likely than not that they are = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dist vs months active (no 1s)\n",
    "sns.scatterplot(x='months_active', y='invoices_paid',\n",
    "                data=dt[dt.invoices_paid > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few massive outliers. Going to rough chop it down and replot\n",
    "invoice_gtr_one = dt.invoices_paid > 1\n",
    "invoice_ls_2000 = dt.invoices_paid < 2000\n",
    "sns.scatterplot(x='months_active', y='invoices_paid',\n",
    "                data=dt[invoice_gtr_one & invoice_ls_2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm, there may be a slight signal but you would expect a stronger trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dist vs years active (no 1s)\n",
    "sns.scatterplot(x='years_active', y='invoices_paid',\n",
    "                data=dt[invoice_gtr_one & invoice_ls_2000])\n",
    "# Slight postive non-linear trend bu there is a HUGE outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoices Paid - Notes\n",
    "\n",
    "It has a weak-ish relationship with time. There are a lot of really heavy users of the platform that dominate the market. Let's zoom into the first year and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at invoices pad in the first few months (among those only active for a shorter period of time)\n",
    "sns.scatterplot(x='months_active',\n",
    "                y='invoices_paid',\n",
    "                data=dt[dt['years_active'] < 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating invoices / time active\n",
    "dt['invoices_per_month'] = dt['invoices_paid'] / \\\n",
    "    dt['months_active']\n",
    "sns.distplot(dt.invoices_per_month)\n",
    "print(dt.invoices_per_month.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded on zero with a long tail. Continues to sell that there are some serious power users.\n",
    "# Average invoice per month is equal to one, but I left in the 1s that could be zeros. . .\n",
    "# Real average is likely near zero.\n",
    "\n",
    "# The question now is: Does this mean differ by any characteristic that I observe in the data?\n",
    "# For people with a different skill set (Andriod) do they have a higher mean invoice/month rate?\n",
    "# For people in different regions do they have a higher mean invoice/month rate?\n",
    "# For people with lower hourly rates do they have a higher mean invoice/month rate??\n",
    "\n",
    "# The next important step is to figure out how to use the skills data.\n",
    "# It would be great to try and create clusters of the skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
