{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Hourly Rate\n",
    "\n",
    "This code trains a model to predict what a prospective freelancers hourly rate should be. The model used is a random forest regression model. I also built an AdaBoosted Decision Tree model, but it performs much worse (using 5-fold cross-validation) compared with the turned random forest regression model.\n",
    "\n",
    "I've also built a k-modes (cluster with categorical/numeric mixed data) model. It is currently being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis and Modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# AdaBoost Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Cross-Validation and Accuracy Measures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "# Model Serializing (export to web-app)\n",
    "import pickle\n",
    "\n",
    "# Packages for PostgreSQL Import\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# Packages for K-Modes Cluster\n",
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names for accessing SQL database\n",
    "# Ideally move these to environment variables.\n",
    "\n",
    "dbname = \"freelance_db\"\n",
    "username = os.environ['USER']\n",
    "pswd = os.environ['SQLPSWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to SQL Database\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)\n",
    "\n",
    "# Import Analysis Dataset\n",
    "sql_query = \"\"\"SELECT * FROM analysis_table;\"\"\"\n",
    "analysis_dt = pd.read_sql_query(sql_query, con)\n",
    "\n",
    "sql_query = \"\"\"SELECT * FROM embeddings_table;\"\"\"\n",
    "embeddings = pd.read_sql_query(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some cleaning. Removing columns that have a continuous analog in the model.\n",
    "analysis_dt = analysis_dt.drop(['has_rating'], axis=1)\n",
    "analysis_dt = analysis_dt.drop(['rating'], axis = 1)\n",
    "analysis_dt = analysis_dt.drop(['index'], axis=1)\n",
    "analysis_dt = analysis_dt.drop(['months_active'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dt.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Estimating a Random Forest Regression to Estimate Hourly-Rate\n",
    "\n",
    "Notes:\n",
    "    - Remove extreme outliers\n",
    "    - Next model probability of getting a job?\n",
    "    - Convert to a clustering algorithm and present a range of estimates?\n",
    "    - Bootstrap to get a range of estimates?\n",
    "    - Make suggestions (Increase bio length by 10 and you can charge X more)\n",
    "        - \"Here are bios for users similar to you\" etc. etc.\n",
    "    - Focus on helping users build up their profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to numpy arrays and saving column names\n",
    "y = np.array(analysis_dt['hourly_rate'])\n",
    "\n",
    "analysis_dt = analysis_dt.drop(['hourly_rate'], axis = 1)\n",
    "feature_list = list(analysis_dt.columns)\n",
    "\n",
    "X = np.array(analysis_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Baseline\n",
    "baseline_preds = y_train.mean()\n",
    "\n",
    "# Baseline Errors\n",
    "baseline_errors = abs(baseline_preds - y_train)\n",
    "\n",
    "# Baseline:\n",
    "print('Mean Absolute Error (naive average): ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References for GridSearchCV\n",
    "# 1 - https://scikit-learn.org/stable/modules/ensemble.html#random-forest-parameters\n",
    "# 2 - https://stackoverflow.com/questions/35097003/cross-validation-decision-trees-in-sklearn\n",
    "# References for Random Forest Regression\n",
    "# 1 - https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "# 2 - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "# Creating parameter grid\n",
    "parameters = {\"max_features\": [\"auto\", \"sqrt\"], \"n_estimators\": [\n",
    "    100, 300, 500, 700, 900, 1100, 1300, 1500, 1700, 2000]}\n",
    "\n",
    "# Creating Grid Search Class\n",
    "clf = GridSearchCV(RandomForestRegressor(), parameters, n_jobs=4, verbose=True, \n",
    "                   scoring=\"neg_mean_squared_error\",\n",
    "                   refit=True)\n",
    "\n",
    "# Running Grid Search\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Saving best model\n",
    "rfr_model = clf.best_estimator_\n",
    "\n",
    "# Printing results\n",
    "print(round(clf.best_score_,2), clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Grid Search CV Results\n",
    "# Saving results to pandas data frame\n",
    "grid_search_results = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "# Plotting\n",
    "sns.scatterplot(x=list(grid_search_results.index), \n",
    "               y=grid_search_results.mean_test_score*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading serialized model from pickle\n",
    "# filename = os.environ['PWD'] + \"/scripts/finalized_model.sav\"\n",
    "# rfr_model = pickle.load(open(filename, 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = rfr_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute error (comparison with baseline)\n",
    "errors = abs(preds - y_train)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, preds))\n",
    "\n",
    "# The coefficient of determination (R2)\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, preds))\n",
    "\n",
    "# Does much better than the mean with regard to mean absolute error\n",
    "print(\"A \", round((np.mean(errors)-19.49)/19.49,3)*-100,\n",
    "      \"percent improvement over the mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting True Hourly Rates vs Predicted Hourly Rates\n",
    "sns.scatterplot(x = y_train, y = preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting AdaBoost Model\n",
    "The reason to fit this model is that iteratively re-weights observations based on how poorly the model predicts them. This pushes the model to finding a way to predict observations other models may miss. I am concerned, however, if it will overfit to outliers.\n",
    "\n",
    "It performs poorly compared to the random forest regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameter grid\n",
    "parameters = {\"n_estimators\": [1, 3, 5, 10, 25, 50, 75, 100, 125, 150],\n",
    "              \"base_estimator__max_depth\": [3, 5, 7, 9, 10, 11]}\n",
    "\n",
    "regr_1 = DecisionTreeRegressor()\n",
    "regr_2 = AdaBoostRegressor(base_estimator=regr_1)\n",
    "\n",
    "# Creating Grid Search Class\n",
    "clf = GridSearchCV(regr_2, parameters, n_jobs=4, verbose=True)\n",
    "\n",
    "# Running Grid Search\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Saving best model\n",
    "adaboost_model = clf.best_estimator_\n",
    "\n",
    "# Printing results\n",
    "print(round(clf.best_score_, 2), clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds_ada = adaboost_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute error (comparison with baseline)\n",
    "errors = abs(preds_ada - y_train)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "# The mean squared error \n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, preds_ada))\n",
    "\n",
    "# The coefficient of determination (R2)\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, preds_ada))\n",
    "\n",
    "# Does much better than the mean with regard to mean absolute error\n",
    "print(\"A \", round((np.mean(errors)-19.12)/19.12,2)*-100,\n",
    "      \"percent improvement over the mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting True Hourly Rates vs Predicted Hourly Rates\n",
    "sns.scatterplot(x = y_train, y = preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Model\n",
    "\n",
    "Putting the random forest regression model (tuned) into production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model with pickle\n",
    "filename = '/Users/Metaverse/Desktop/Insight/projects/myrate/scripts/finalized_model.sav'\n",
    "pickle.dump(rfr_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing Ground\n",
    "\n",
    "## Model with embeddings\n",
    "\n",
    "I can change the number of embeddings in the bios_word2vec notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'profile_url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb6e26d9b6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Merging on profile_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"profile_url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insight/projects/myrate/conda-env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7295\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7296\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7297\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7298\u001b[0m         )\n\u001b[1;32m   7299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insight/projects/myrate/conda-env/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insight/projects/myrate/conda-env/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insight/projects/myrate/conda-env/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    994\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insight/projects/myrate/conda-env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'profile_url'"
     ]
    }
   ],
   "source": [
    "# Removing index col from embeddings\n",
    "embeddings = embeddings.drop(['index'], axis = 1)\n",
    "\n",
    "# Merging on profile_url\n",
    "test = analysis_dt.merge(embeddings, on = \"profile_url\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building K-Modes Model to Cluster Users\n",
    "This is an experimental section. I want to try and create clusters to then provide a range of values ones hourly rate may take. However, the problem with clustering methods (as always) is that it is more of an art than actual science for determining when to stop. I don't think there are very clear clusters in this data. I may be better off running word2vec on the bios (large text) and clustering off that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found K-Modes on stackoverflow\n",
    "# Following the package documentation\n",
    "# Ref: https://pypi.org/project/kmodes/\n",
    "# Ref: https://stackoverflow.com/questions/42639824/python-k-modes-explanation\n",
    "# Ref: https://www.kaggle.com/ashydv/bank-customer-clustering-k-modes-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling with K Modes\n",
    "cost = []\n",
    "for num_clusters in list(range(1, 21)):\n",
    "    kmode = KModes(n_clusters=num_clusters, init=\"Huang\", verbose=0, random_state=42)\n",
    "    kmode.fit_predict(X)\n",
    "    cost.append(kmode.cost_)\n",
    "    print(\"Finished Cluster: \" + str(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cost function result vs number of clusters\n",
    "number_of_clusters = np.array([i for i in range(1, 21, 1)])\n",
    "plt.plot(number_of_clusters, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmode = KModes(n_clusters=6, init='Huang', verbose=0)\n",
    "clusters = kmode.fit_predict(X)\n",
    "\n",
    "kmodes = kmode.cluster_centroids_\n",
    "shape = kmodes.shape\n",
    "\n",
    "for i in range(shape[0]):\n",
    "    if sum(kmodes[i, :]) == 0:\n",
    "        print(\"\\ncluster \" + str(i) + \": \")\n",
    "        print(\"no-skills cluster\")\n",
    "    else:\n",
    "        print(\"\\ncluster \" + str(i) + \": \")\n",
    "        cent = kmodes[i, :]\n",
    "        for j in analysis_dt.columns[np.nonzero(cent)]:\n",
    "            print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_assigned = kmode.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(clust_assigned, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dt['cluster'] = list(clust_assigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dt[analysis_dt.cluster == 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
