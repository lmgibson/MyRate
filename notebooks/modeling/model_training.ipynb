{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Hourly Rate\n",
    "\n",
    "This code trains a model to predict what a prospective freelancers hourly rate should be. The model used is a random forest regression model. I also built an AdaBoosted Decision Tree model, but it performs much worse (using 5-fold cross-validation) compared with the turned random forest regression model.\n",
    "\n",
    "I've also built a k-modes (cluster with categorical/numeric mixed data) model. It is currently being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep\n",
    "\n",
    "## Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis and Modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# AdaBoost Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# LASSO\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cross-Validation and Accuracy Measures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, mean_absolute_error\n",
    "\n",
    "# Model Serializing (export to web-app)\n",
    "import pickle\n",
    "\n",
    "# Packages for PostgreSQL Import\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# Packages for K-Modes Cluster\n",
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964, 114)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Names for accessing SQL database\n",
    "dbname = \"freelance_db\"\n",
    "username = os.environ['USER']\n",
    "pswd = os.environ['SQLPSWD']\n",
    "\n",
    "# Connect to SQL Database\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)\n",
    "\n",
    "# Importing Data\n",
    "sql_query = \"\"\"SELECT * FROM analysis_dummies_table;\"\"\"\n",
    "analysis_dt = pd.read_sql_query(sql_query, con)\n",
    "\n",
    "sql_query = \"\"\"SELECT * FROM embeddings_table;\"\"\"\n",
    "embeddings = pd.read_sql_query(sql_query, con)\n",
    "\n",
    "# Doing some cleaning. Removing columns that have a continuous analog in the model.\n",
    "analysis_dt = analysis_dt.drop(['index'], axis=1)\n",
    "analysis_dt = analysis_dt.drop(['first_skill'], axis = 1)\n",
    "\n",
    "# Removing index col from embeddings\n",
    "embeddings = embeddings.drop(['index'], axis = 1)\n",
    "embeddings['profile_url'] = \"https://www.guru.com\" + embeddings['profile_url']\n",
    "\n",
    "# Merging on profile_url\n",
    "analysis_dt = analysis_dt.merge(embeddings, how = \"left\", \n",
    "                                left_on = \"profile_url\", right_on= \"profile_url\")\n",
    "analysis_dt = analysis_dt.drop(['profile_url'], axis = 1)\n",
    "analysis_dt = analysis_dt.fillna(0)\n",
    "\n",
    "# Cleaning avg_word_length and bio_word count\n",
    "analysis_dt.loc[analysis_dt['bio_length'] == 0, ['bio_word_count','avg_word_length']] = 0\n",
    "\n",
    "# Removing Crazy Outliers\n",
    "analysis_dt.drop(analysis_dt[analysis_dt['hourly_rate'] > 100].index, inplace = True)\n",
    "analysis_dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to numpy arrays and saving column names\n",
    "y = np.array(analysis_dt['hourly_rate'])\n",
    "\n",
    "analysis_dt = analysis_dt.drop(['hourly_rate'], axis = 1)\n",
    "feature_list = list(analysis_dt.columns)\n",
    "\n",
    "X = np.array(analysis_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data into DMatrix\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtrain.save_binary((os.environ['PWD'] + '/data/cleaned/train.buffer'))\n",
    "dtest.save_binary((os.environ['PWD'] + '/data/cleaned/test.buffer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:20.17713\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:17.22973\n",
      "[2]\tTest-mae:16.08314\n",
      "[3]\tTest-mae:15.58959\n",
      "[4]\tTest-mae:15.50499\n",
      "[5]\tTest-mae:15.74091\n",
      "[6]\tTest-mae:16.07302\n",
      "[7]\tTest-mae:16.19855\n",
      "[8]\tTest-mae:16.46500\n",
      "[9]\tTest-mae:16.45968\n",
      "[10]\tTest-mae:16.55776\n",
      "[11]\tTest-mae:16.59185\n",
      "[12]\tTest-mae:16.74085\n",
      "[13]\tTest-mae:16.83016\n",
      "[14]\tTest-mae:16.87075\n",
      "Stopping. Best iteration:\n",
      "[4]\tTest-mae:15.50499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model without Tuning\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "    'eval_metric': \"mae\"\n",
    "}\n",
    "\n",
    "num_boost_round = 999\n",
    "\n",
    "# Cross-Validated XGBoost\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# MAE With Default Params = 15.50499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=2, min_child_weight=2\n",
      "\tMAE 15.4107316 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=4\n",
      "\tMAE 15.416767400000001 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=6\n",
      "\tMAE 15.416767400000001 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=8\n",
      "\tMAE 15.421375399999999 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=10\n",
      "\tMAE 15.419965999999999 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=12\n",
      "\tMAE 15.389829599999999 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=14\n",
      "\tMAE 15.3914782 for 5 rounds\n",
      "CV with max_depth=2, min_child_weight=16\n",
      "\tMAE 15.409867 for 4 rounds\n",
      "CV with max_depth=2, min_child_weight=18\n",
      "\tMAE 15.423952400000001 for 6 rounds\n",
      "CV with max_depth=4, min_child_weight=2\n",
      "\tMAE 15.6884388 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=4\n",
      "\tMAE 15.628003999999999 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=6\n",
      "\tMAE 15.5467798 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=8\n",
      "\tMAE 15.538757999999998 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=10\n",
      "\tMAE 15.667288600000001 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=12\n",
      "\tMAE 15.606866599999998 for 5 rounds\n",
      "CV with max_depth=4, min_child_weight=14\n",
      "\tMAE 15.5035654 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=16\n",
      "\tMAE 15.656907 for 4 rounds\n",
      "CV with max_depth=4, min_child_weight=18\n",
      "\tMAE 15.4990312 for 4 rounds\n",
      "CV with max_depth=6, min_child_weight=2\n",
      "\tMAE 16.1451134 for 5 rounds\n",
      "CV with max_depth=6, min_child_weight=4\n",
      "\tMAE 16.0368718 for 4 rounds\n",
      "CV with max_depth=6, min_child_weight=6\n",
      "\tMAE 15.877258000000001 for 5 rounds\n",
      "CV with max_depth=6, min_child_weight=8\n",
      "\tMAE 15.778038 for 4 rounds\n",
      "CV with max_depth=6, min_child_weight=10\n",
      "\tMAE 15.6698008 for 5 rounds\n",
      "CV with max_depth=6, min_child_weight=12\n",
      "\tMAE 15.690865200000001 for 4 rounds\n",
      "CV with max_depth=6, min_child_weight=14\n",
      "\tMAE 15.602258799999998 for 4 rounds\n",
      "CV with max_depth=6, min_child_weight=16\n",
      "\tMAE 15.5197976 for 4 rounds\n",
      "CV with max_depth=6, min_child_weight=18\n",
      "\tMAE 15.618485799999998 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=2\n",
      "\tMAE 16.206518999999997 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=4\n",
      "\tMAE 16.3073184 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=6\n",
      "\tMAE 16.054198399999997 for 5 rounds\n",
      "CV with max_depth=8, min_child_weight=8\n",
      "\tMAE 15.979573400000001 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=10\n",
      "\tMAE 16.026203000000002 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=12\n",
      "\tMAE 15.8947696 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=14\n",
      "\tMAE 15.870534800000001 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=16\n",
      "\tMAE 15.864667800000001 for 4 rounds\n",
      "CV with max_depth=8, min_child_weight=18\n",
      "\tMAE 15.685914200000003 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=2\n",
      "\tMAE 16.5172866 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=4\n",
      "\tMAE 16.636946799999997 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 16.2673646 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=8\n",
      "\tMAE 15.9704788 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=10\n",
      "\tMAE 15.957322999999999 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=12\n",
      "\tMAE 15.9032986 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=14\n",
      "\tMAE 15.5972884 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=16\n",
      "\tMAE 15.870057800000001 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=18\n",
      "\tMAE 15.631514000000001 for 4 rounds\n",
      "CV with max_depth=12, min_child_weight=2\n",
      "\tMAE 17.006274 for 5 rounds\n",
      "CV with max_depth=12, min_child_weight=4\n",
      "\tMAE 16.5310536 for 5 rounds\n",
      "CV with max_depth=12, min_child_weight=6\n",
      "\tMAE 16.412661 for 4 rounds\n",
      "CV with max_depth=12, min_child_weight=8\n",
      "\tMAE 16.4713146 for 5 rounds\n",
      "CV with max_depth=12, min_child_weight=10\n",
      "\tMAE 16.102540400000002 for 4 rounds\n",
      "CV with max_depth=12, min_child_weight=12\n",
      "\tMAE 15.962761200000003 for 5 rounds\n",
      "CV with max_depth=12, min_child_weight=14\n",
      "\tMAE 15.8565618 for 4 rounds\n",
      "CV with max_depth=12, min_child_weight=16\n",
      "\tMAE 15.792280600000002 for 5 rounds\n",
      "CV with max_depth=12, min_child_weight=18\n",
      "\tMAE 15.641506800000002 for 4 rounds\n",
      "CV with max_depth=14, min_child_weight=2\n",
      "\tMAE 16.797994 for 6 rounds\n",
      "CV with max_depth=14, min_child_weight=4\n",
      "\tMAE 16.7102654 for 5 rounds\n",
      "CV with max_depth=14, min_child_weight=6\n",
      "\tMAE 16.280585000000002 for 4 rounds\n",
      "CV with max_depth=14, min_child_weight=8\n",
      "\tMAE 16.4246102 for 4 rounds\n",
      "CV with max_depth=14, min_child_weight=10\n",
      "\tMAE 16.1193916 for 4 rounds\n",
      "CV with max_depth=14, min_child_weight=12\n",
      "\tMAE 15.9184134 for 6 rounds\n",
      "CV with max_depth=14, min_child_weight=14\n",
      "\tMAE 15.856317999999998 for 4 rounds\n",
      "CV with max_depth=14, min_child_weight=16\n",
      "\tMAE 15.9316848 for 4 rounds\n",
      "CV with max_depth=14, min_child_weight=18\n",
      "\tMAE 15.635207000000003 for 4 rounds\n",
      "CV with max_depth=16, min_child_weight=2\n",
      "\tMAE 16.732106199999997 for 7 rounds\n",
      "CV with max_depth=16, min_child_weight=4\n",
      "\tMAE 16.8558872 for 5 rounds\n",
      "CV with max_depth=16, min_child_weight=6\n",
      "\tMAE 16.3539064 for 4 rounds\n",
      "CV with max_depth=16, min_child_weight=8\n",
      "\tMAE 16.4435522 for 4 rounds\n",
      "CV with max_depth=16, min_child_weight=10\n",
      "\tMAE 16.131287399999998 for 4 rounds\n",
      "CV with max_depth=16, min_child_weight=12\n",
      "\tMAE 15.902890600000001 for 5 rounds\n",
      "CV with max_depth=16, min_child_weight=14\n",
      "\tMAE 15.865210999999999 for 4 rounds\n",
      "CV with max_depth=16, min_child_weight=16\n",
      "\tMAE 15.8925184 for 5 rounds\n",
      "CV with max_depth=16, min_child_weight=18\n",
      "\tMAE 15.635207000000003 for 4 rounds\n",
      "CV with max_depth=18, min_child_weight=2\n",
      "\tMAE 16.6964086 for 5 rounds\n",
      "CV with max_depth=18, min_child_weight=4\n",
      "\tMAE 16.739863399999997 for 5 rounds\n",
      "CV with max_depth=18, min_child_weight=6\n",
      "\tMAE 16.353741199999998 for 4 rounds\n",
      "CV with max_depth=18, min_child_weight=8\n",
      "\tMAE 16.433990599999998 for 5 rounds\n",
      "CV with max_depth=18, min_child_weight=10\n",
      "\tMAE 16.131287399999998 for 4 rounds\n",
      "CV with max_depth=18, min_child_weight=12\n",
      "\tMAE 15.9093704 for 5 rounds\n",
      "CV with max_depth=18, min_child_weight=14\n",
      "\tMAE 15.864332399999999 for 4 rounds\n",
      "CV with max_depth=18, min_child_weight=16\n",
      "\tMAE 15.9221458 for 4 rounds\n",
      "CV with max_depth=18, min_child_weight=18\n",
      "\tMAE 15.635207000000003 for 4 rounds\n",
      "Best params: 2, 12, MAE: 15.389829599999999\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(2, 20, 2)\n",
    "    for min_child_weight in range(2, 20, 2)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "        max_depth,\n",
    "        min_child_weight))    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best MAE\n",
    "    \n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating params dictionary with selected values\n",
    "params['max_depth'] = 2\n",
    "params['min_child_weight'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 15.3898292 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 15.3874636 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 15.4829522 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 15.450802 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.6\n",
      "\tMAE 15.339092400000002 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.5\n",
      "\tMAE 15.360109799999998 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.4\n",
      "\tMAE 15.5965004 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.3\n",
      "\tMAE 15.702760799999998 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.2\n",
      "\tMAE 15.879101400000001 for 4 rounds\n",
      "CV with subsample=1.0, colsample=0.1\n",
      "\tMAE 15.9938606 for 4 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 15.473707399999999 for 4 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 15.462648999999999 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 15.425058400000001 for 4 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 15.4145232 for 4 rounds\n",
      "CV with subsample=0.9, colsample=0.6\n",
      "\tMAE 15.4369086 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.5\n",
      "\tMAE 15.445372600000002 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.4\n",
      "\tMAE 15.528320000000003 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.3\n",
      "\tMAE 15.6255808 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.2\n",
      "\tMAE 15.8163262 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.1\n",
      "\tMAE 16.016804 for 5 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 15.431360399999999 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 15.4379734 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 15.4124348 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 15.3843006 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.6\n",
      "\tMAE 15.489363800000001 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.5\n",
      "\tMAE 15.550436999999999 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.4\n",
      "\tMAE 15.660156 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.3\n",
      "\tMAE 15.7066852 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.2\n",
      "\tMAE 15.8790944 for 19 rounds\n",
      "CV with subsample=0.8, colsample=0.1\n",
      "\tMAE 15.952202600000001 for 18 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 15.322302200000001 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 15.3552388 for 4 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 15.4484238 for 4 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 15.453485599999999 for 4 rounds\n",
      "CV with subsample=0.7, colsample=0.6\n",
      "\tMAE 15.5217446 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.5\n",
      "\tMAE 15.590458000000002 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.4\n",
      "\tMAE 15.675661 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.3\n",
      "\tMAE 15.672057 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.2\n",
      "\tMAE 15.834721199999999 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.1\n",
      "\tMAE 15.9367356 for 7 rounds\n",
      "CV with subsample=0.6, colsample=1.0\n",
      "\tMAE 15.314624999999998 for 4 rounds\n",
      "CV with subsample=0.6, colsample=0.9\n",
      "\tMAE 15.3067758 for 4 rounds\n",
      "CV with subsample=0.6, colsample=0.8\n",
      "\tMAE 15.294563 for 4 rounds\n",
      "CV with subsample=0.6, colsample=0.7\n",
      "\tMAE 15.2778454 for 4 rounds\n",
      "CV with subsample=0.6, colsample=0.6\n",
      "\tMAE 15.429803999999999 for 5 rounds\n",
      "CV with subsample=0.6, colsample=0.5\n",
      "\tMAE 15.3011126 for 5 rounds\n",
      "CV with subsample=0.6, colsample=0.4\n",
      "\tMAE 15.5028034 for 5 rounds\n",
      "CV with subsample=0.6, colsample=0.3\n",
      "\tMAE 15.6700404 for 5 rounds\n",
      "CV with subsample=0.6, colsample=0.2\n",
      "\tMAE 15.792199199999999 for 7 rounds\n",
      "CV with subsample=0.6, colsample=0.1\n",
      "\tMAE 16.0692286 for 6 rounds\n",
      "CV with subsample=0.5, colsample=1.0\n",
      "\tMAE 15.3645384 for 4 rounds\n",
      "CV with subsample=0.5, colsample=0.9\n",
      "\tMAE 15.300624200000001 for 4 rounds\n",
      "CV with subsample=0.5, colsample=0.8\n",
      "\tMAE 15.458096000000001 for 4 rounds\n",
      "CV with subsample=0.5, colsample=0.7\n",
      "\tMAE 15.565000000000001 for 4 rounds\n",
      "CV with subsample=0.5, colsample=0.6\n",
      "\tMAE 15.5293004 for 5 rounds\n",
      "CV with subsample=0.5, colsample=0.5\n",
      "\tMAE 15.725832800000001 for 5 rounds\n",
      "CV with subsample=0.5, colsample=0.4\n",
      "\tMAE 15.546893 for 5 rounds\n",
      "CV with subsample=0.5, colsample=0.3\n",
      "\tMAE 15.761154 for 5 rounds\n",
      "CV with subsample=0.5, colsample=0.2\n",
      "\tMAE 15.858542199999999 for 5 rounds\n",
      "CV with subsample=0.5, colsample=0.1\n",
      "\tMAE 16.1139904 for 5 rounds\n",
      "Best params: 0.6, 0.7, MAE: 15.2778454\n"
     ]
    }
   ],
   "source": [
    "# Tuning subsample and colsample_bytree\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(5,11)]\n",
    "    for colsample in [i/10. for i in range(1,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "        \n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n",
    "\n",
    "params['subsample'] = best_params[0]\n",
    "params['colsample_bytree'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tMAE 15.2778454 for 4 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "\tMAE 15.338374400000001 for 7 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "\tMAE 15.401718599999999 for 16 rounds\n",
      "\n",
      "CV with eta=0.07\n",
      "\tMAE 15.3685294 for 25 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "\tMAE 15.342504 for 37 rounds\n",
      "\n",
      "CV with eta=0.02\n",
      "\tMAE 15.2733768 for 94 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "\tMAE 15.3112674 for 183 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "\tMAE 15.3117074 for 371 rounds\n",
      "\n",
      "Best params: 0.02, MAE: 15.2733768\n"
     ]
    }
   ],
   "source": [
    "# Tuning ETA (learning rate)\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .07, .05, .02, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))    # We update our parameters\n",
    "    params['eta'] = eta    # Run and time CV\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics=['mae'],\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best score\n",
    "    \n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\n",
    "\n",
    "params['eta'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:26.85500\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:26.28794\n",
      "[2]\tTest-mae:25.71911\n",
      "[3]\tTest-mae:25.18005\n",
      "[4]\tTest-mae:24.63767\n",
      "[5]\tTest-mae:24.11353\n",
      "[6]\tTest-mae:23.58127\n",
      "[7]\tTest-mae:23.11086\n",
      "[8]\tTest-mae:22.69963\n",
      "[9]\tTest-mae:22.29082\n",
      "[10]\tTest-mae:21.91689\n",
      "[11]\tTest-mae:21.56964\n",
      "[12]\tTest-mae:21.22121\n",
      "[13]\tTest-mae:20.87109\n",
      "[14]\tTest-mae:20.56210\n",
      "[15]\tTest-mae:20.26608\n",
      "[16]\tTest-mae:19.96790\n",
      "[17]\tTest-mae:19.69532\n",
      "[18]\tTest-mae:19.44053\n",
      "[19]\tTest-mae:19.20138\n",
      "[20]\tTest-mae:18.96594\n",
      "[21]\tTest-mae:18.73932\n",
      "[22]\tTest-mae:18.52958\n",
      "[23]\tTest-mae:18.34005\n",
      "[24]\tTest-mae:18.17947\n",
      "[25]\tTest-mae:18.00093\n",
      "[26]\tTest-mae:17.84043\n",
      "[27]\tTest-mae:17.68801\n",
      "[28]\tTest-mae:17.53601\n",
      "[29]\tTest-mae:17.39289\n",
      "[30]\tTest-mae:17.24901\n",
      "[31]\tTest-mae:17.12037\n",
      "[32]\tTest-mae:17.00357\n",
      "[33]\tTest-mae:16.90865\n",
      "[34]\tTest-mae:16.82658\n",
      "[35]\tTest-mae:16.74205\n",
      "[36]\tTest-mae:16.67019\n",
      "[37]\tTest-mae:16.59058\n",
      "[38]\tTest-mae:16.51202\n",
      "[39]\tTest-mae:16.44210\n",
      "[40]\tTest-mae:16.38360\n",
      "[41]\tTest-mae:16.34487\n",
      "[42]\tTest-mae:16.29872\n",
      "[43]\tTest-mae:16.25579\n",
      "[44]\tTest-mae:16.21808\n",
      "[45]\tTest-mae:16.17230\n",
      "[46]\tTest-mae:16.12843\n",
      "[47]\tTest-mae:16.09385\n",
      "[48]\tTest-mae:16.06019\n",
      "[49]\tTest-mae:16.01956\n",
      "[50]\tTest-mae:15.99685\n",
      "[51]\tTest-mae:15.97220\n",
      "[52]\tTest-mae:15.95377\n",
      "[53]\tTest-mae:15.93664\n",
      "[54]\tTest-mae:15.91512\n",
      "[55]\tTest-mae:15.90384\n",
      "[56]\tTest-mae:15.88344\n",
      "[57]\tTest-mae:15.87261\n",
      "[58]\tTest-mae:15.85395\n",
      "[59]\tTest-mae:15.83448\n",
      "[60]\tTest-mae:15.82335\n",
      "[61]\tTest-mae:15.80406\n",
      "[62]\tTest-mae:15.78997\n",
      "[63]\tTest-mae:15.76575\n",
      "[64]\tTest-mae:15.75274\n",
      "[65]\tTest-mae:15.74500\n",
      "[66]\tTest-mae:15.72595\n",
      "[67]\tTest-mae:15.71181\n",
      "[68]\tTest-mae:15.71137\n",
      "[69]\tTest-mae:15.70362\n",
      "[70]\tTest-mae:15.69823\n",
      "[71]\tTest-mae:15.68438\n",
      "[72]\tTest-mae:15.67837\n",
      "[73]\tTest-mae:15.67582\n",
      "[74]\tTest-mae:15.67815\n",
      "[75]\tTest-mae:15.67517\n",
      "[76]\tTest-mae:15.67999\n",
      "[77]\tTest-mae:15.68026\n",
      "[78]\tTest-mae:15.68890\n",
      "[79]\tTest-mae:15.69997\n",
      "[80]\tTest-mae:15.70349\n",
      "[81]\tTest-mae:15.71423\n",
      "[82]\tTest-mae:15.71591\n",
      "[83]\tTest-mae:15.72558\n",
      "[84]\tTest-mae:15.73680\n",
      "[85]\tTest-mae:15.74337\n",
      "Stopping. Best iteration:\n",
      "[75]\tTest-mae:15.67517\n",
      "\n",
      "Best MAE: 15.68 in 76 rounds\n"
     ]
    }
   ],
   "source": [
    "# Train Final Model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:26.85500\n",
      "[1]\tTest-mae:26.28794\n",
      "[2]\tTest-mae:25.71911\n",
      "[3]\tTest-mae:25.18005\n",
      "[4]\tTest-mae:24.63767\n",
      "[5]\tTest-mae:24.11353\n",
      "[6]\tTest-mae:23.58127\n",
      "[7]\tTest-mae:23.11086\n",
      "[8]\tTest-mae:22.69963\n",
      "[9]\tTest-mae:22.29083\n",
      "[10]\tTest-mae:21.91690\n",
      "[11]\tTest-mae:21.56963\n",
      "[12]\tTest-mae:21.22121\n",
      "[13]\tTest-mae:20.87108\n",
      "[14]\tTest-mae:20.56210\n",
      "[15]\tTest-mae:20.26608\n",
      "[16]\tTest-mae:19.96790\n",
      "[17]\tTest-mae:19.69532\n",
      "[18]\tTest-mae:19.44053\n",
      "[19]\tTest-mae:19.20138\n",
      "[20]\tTest-mae:18.96594\n",
      "[21]\tTest-mae:18.73932\n",
      "[22]\tTest-mae:18.52958\n",
      "[23]\tTest-mae:18.34005\n",
      "[24]\tTest-mae:18.17947\n",
      "[25]\tTest-mae:18.00093\n",
      "[26]\tTest-mae:17.84043\n",
      "[27]\tTest-mae:17.68801\n",
      "[28]\tTest-mae:17.53601\n",
      "[29]\tTest-mae:17.39289\n",
      "[30]\tTest-mae:17.24900\n",
      "[31]\tTest-mae:17.12037\n",
      "[32]\tTest-mae:17.00357\n",
      "[33]\tTest-mae:16.90865\n",
      "[34]\tTest-mae:16.82658\n",
      "[35]\tTest-mae:16.74205\n",
      "[36]\tTest-mae:16.67019\n",
      "[37]\tTest-mae:16.59058\n",
      "[38]\tTest-mae:16.51202\n",
      "[39]\tTest-mae:16.44210\n",
      "[40]\tTest-mae:16.38360\n",
      "[41]\tTest-mae:16.34487\n",
      "[42]\tTest-mae:16.29872\n",
      "[43]\tTest-mae:16.25579\n",
      "[44]\tTest-mae:16.21808\n",
      "[45]\tTest-mae:16.17230\n",
      "[46]\tTest-mae:16.12843\n",
      "[47]\tTest-mae:16.09385\n",
      "[48]\tTest-mae:16.06018\n",
      "[49]\tTest-mae:16.01956\n",
      "[50]\tTest-mae:15.99685\n",
      "[51]\tTest-mae:15.97220\n",
      "[52]\tTest-mae:15.95377\n",
      "[53]\tTest-mae:15.93664\n",
      "[54]\tTest-mae:15.91512\n",
      "[55]\tTest-mae:15.90384\n",
      "[56]\tTest-mae:15.88344\n",
      "[57]\tTest-mae:15.87261\n",
      "[58]\tTest-mae:15.85396\n",
      "[59]\tTest-mae:15.83448\n",
      "[60]\tTest-mae:15.82335\n",
      "[61]\tTest-mae:15.80406\n",
      "[62]\tTest-mae:15.78997\n",
      "[63]\tTest-mae:15.76575\n",
      "[64]\tTest-mae:15.75274\n",
      "[65]\tTest-mae:15.74500\n",
      "[66]\tTest-mae:15.72595\n",
      "[67]\tTest-mae:15.71181\n",
      "[68]\tTest-mae:15.71137\n",
      "[69]\tTest-mae:15.70362\n",
      "[70]\tTest-mae:15.69823\n",
      "[71]\tTest-mae:15.68438\n",
      "[72]\tTest-mae:15.67837\n",
      "[73]\tTest-mae:15.67582\n",
      "[74]\tTest-mae:15.67815\n",
      "[75]\tTest-mae:15.67517\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting model\n",
    "filename = os.environ['PWD'] + '/scripts/models/model_xgb.model'\n",
    "# filename_dump = os.environ['PWD'] + '/scripts/models/dump.raw.txt'\n",
    "\n",
    "best_model.save_model(filename)\n",
    "# best_model.dump_model(filename_dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Metaverse/Desktop/Insight/projects/myrate/scripts/model_lasso.sav\n"
     ]
    }
   ],
   "source": [
    "# Running model\n",
    "model_lasso = LassoCV(cv=20).fit(X_train, y_train)\n",
    "\n",
    "# Saving model with pickle\n",
    "filename = os.environ['PWD'] + '/scripts/models/model_lasso.sav'\n",
    "pickle.dump(model_lasso, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Random Forest Regression\n",
    "## Estimating a Random Forest Regression to Estimate Hourly-Rate\n",
    "\n",
    "Notes:\n",
    "    - Next model probability of getting a job?\n",
    "    - Convert to a clustering algorithm and present a range of estimates?\n",
    "    - Bootstrap to get a range of estimates?\n",
    "    - Make suggestions (Increase bio length by 10 and you can charge X more)\n",
    "        - \"Here are bios for users similar to you\" etc. etc.\n",
    "    - Focus on helping users build up their profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 20.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.72 {'max_depth': 5, 'max_features': 'auto', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# References for GridSearchCV\n",
    "# 1 - https://scikit-learn.org/stable/modules/ensemble.html#random-forest-parameters\n",
    "# 2 - https://stackoverflow.com/questions/35097003/cross-validation-decision-trees-in-sklearn\n",
    "# References for Random Forest Regression\n",
    "# 1 - https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "# 2 - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "# Creating parameter grid\n",
    "parameters = {\"max_features\": [\"auto\", \"sqrt\"], \n",
    "              \"n_estimators\": [100, 500, 900, 1300, 1500], \n",
    "              \"max_depth\": [None,5,10,20]}\n",
    "\n",
    "# Creating Grid Search Class\n",
    "clf = GridSearchCV(RandomForestRegressor(), parameters, n_jobs=4, verbose=True, \n",
    "                   scoring=\"neg_mean_absolute_error\",\n",
    "                   refit=True, cv = 3)\n",
    "\n",
    "# Running Grid Search\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Saving best model\n",
    "model_rfr = clf.best_estimator_\n",
    "\n",
    "# Printing results\n",
    "print(round(clf.best_score_,2), clf.best_params_)\n",
    "\n",
    "# Exporting model\n",
    "filename = os.environ['PWD'] + '/scripts/models/model_rfr.sav'\n",
    "pickle.dump(model_rfr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting AdaBoost Model\n",
    "The reason to fit this model is that iteratively re-weights observations based on how poorly the model predicts them. This pushes the model to finding a way to predict observations other models may miss. I am concerned, however, if it will overfit to outliers.\n",
    "\n",
    "It performs poorly compared to the random forest regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 {'base_estimator__max_depth': 7, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "# Creating parameter grid\n",
    "parameters = {\"n_estimators\": [1, 3, 5, 10, 25, 50, 75, 100, 125, 150],\n",
    "              \"base_estimator__max_depth\": [3, 5, 7, 9, 10, 11]}\n",
    "\n",
    "regr_1 = DecisionTreeRegressor()\n",
    "regr_2 = AdaBoostRegressor(base_estimator=regr_1)\n",
    "\n",
    "# Creating Grid Search Class\n",
    "clf = GridSearchCV(regr_2, parameters, n_jobs=4, verbose=True)\n",
    "\n",
    "# Running Grid Search\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Saving best model\n",
    "model_ada = clf.best_estimator_\n",
    "\n",
    "# Printing results\n",
    "print(round(clf.best_score_, 2), clf.best_params_)\n",
    "\n",
    "# Exporting Model\n",
    "filename = os.environ['PWD'] + '/scripts/models/model_ada.sav'\n",
    "pickle.dump(model_ada, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
