{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details_scrape(url):\n",
    "    \"\"\"\n",
    "    Uses selenium to scrape additional information contained in a sub-menu\n",
    "    \n",
    "    Clicks the first box, guru throws up a log-in, goes back, opens all the boxes\n",
    "    and then finishes by extracting all the html from each box.\n",
    "    \n",
    "    This takes in a single URL (string) and extracts from that. One problem that may arise\n",
    "    is if it doesn't throw the log-in box and the driver tries to go back a page.\n",
    "    However, I think we can get around this by just loading each URL new. \n",
    "    \n",
    "    May be more efficient to page through? That's for another time.\n",
    "    \n",
    "    RETURNS: list of names and list of HTML for each details box.\n",
    "    \n",
    "    Test URL:\n",
    "    \"https://www.guru.com/d/freelancers/lc/united-states/california/los-angeles/pg/1/\"\n",
    "    \"\"\"\n",
    "    \n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(url)\n",
    "    login_form = driver.find_elements_by_xpath('//button[@class=\"tabControls__button\"]')\n",
    "\n",
    "    time.sleep(2) # Wait to click\n",
    "    login_form[2].click()\n",
    "\n",
    "    time.sleep(2) # Wait for log-in prompt\n",
    "    driver.back() # Go back to main page\n",
    "    time.sleep(2) # Wait to scrape\n",
    "\n",
    "    # Pulling the paths again (they change for some reason)\n",
    "    login_form = driver.find_elements_by_xpath('//button[@class=\"tabControls__button\"]') \n",
    "    counter = 2\n",
    "    \n",
    "    # There are multiple buttons so here I am just clicking the ones I want (2,6,10,...)\n",
    "    for i, val in enumerate(login_form):    \n",
    "        if i == counter:\n",
    "            login_form[i].click()\n",
    "            counter += 4\n",
    "    \n",
    "    print(\"Completed opening all the tabs\")\n",
    "\n",
    "    # Pull elements in the now opened detail boxes\n",
    "        # //div[@class=\"avatarinfo\"]\n",
    "    user_name = driver.find_elements_by_xpath('//div[@class=\"module_avatar freelancerAvatar\"]')\n",
    "    user_detail = driver.find_elements_by_xpath('//ul[@class=\"feedback__stats clearfix\"]')\n",
    "\n",
    "    # Extract text from the names and HTML from the details\n",
    "    # Will parse the detail_html further with beautiful soup\n",
    "    # Each is a list of length equal to the number of users on the page\n",
    "    names = []\n",
    "    for i, val in enumerate(user_name):\n",
    "        names.append(val.get_attribute('innerHTML'))\n",
    "\n",
    "    detail_html = []\n",
    "    for i, val in enumerate(user_detail):\n",
    "        detail_html.append(val.get_attribute('innerHTML'))\n",
    "\n",
    "    driver.close()\n",
    "    print(\"Finished\")\n",
    "    \n",
    "    return names, detail_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details_to_soup(x):\n",
    "    \"\"\"\n",
    "    Takes in a list of raw htmls and parses them with BeautifulSoup.\n",
    "    \n",
    "    Returns a list of cleaner HTMLs (soup objects), \n",
    "    \n",
    "    \"\"\"\n",
    "    soups = []\n",
    "    for i, val in enumerate(x):\n",
    "        soups.append(BeautifulSoup(val,'html.parser'))\n",
    "        \n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_values_to_list(x):\n",
    "    \"\"\"\n",
    "    Takes in a list of soups and extracts the em from them.\n",
    "    \n",
    "    Returns a list with lists where the first element has a list containing the em elements.\n",
    "    The second element also has a list containing the em elements, and so on.\n",
    "    \n",
    "    \"\"\"\n",
    "    values = []\n",
    "    for i, val in enumerate(x):\n",
    "        values.append(val.find_all('em'))\n",
    "        \n",
    "    html_to_string = lambda x: x.string\n",
    "    values_strings = []\n",
    "    for i, val in enumerate(values):\n",
    "        values_strings.append(list(map(html_to_string, val)))\n",
    "        \n",
    "    return values_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_urls_to_list(x):\n",
    "    \"\"\"\n",
    "    Takes in a list of soups and extracts user htmls from them.\n",
    "    \n",
    "    Returns a list with user htmls\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    user_htmls = []\n",
    "    for i, val in enumerate(x):\n",
    "        user_htmls.append(val.a['href'])\n",
    "        \n",
    "    return user_htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_clean_data(names_list,details_list):\n",
    "    \"\"\"\n",
    "    Combines the names and details into a single list of lists.\n",
    "    Dealing with them separately is difficult to follow so I want to combine them ASAP\n",
    "    \n",
    "    Returns single list of lists\n",
    "    \"\"\"\n",
    "    for i, val in enumerate(details_list):\n",
    "        val.insert(0, names_list[i])\n",
    "        \n",
    "    return details_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_into_dataframe(x):\n",
    "    \"\"\"\n",
    "    Takes two lists, the urls and the raw data, and puts them into a pandas dataframe.\n",
    "    \n",
    "    x is URLs\n",
    "    y is raw data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(data = x, columns = [\"url\",\"member_since\",\"earnings_pst_yr\",\"earnings_ever\",\n",
    "                                       \"employers\",\"invoices_paid\",\"largest_employ\"])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed opening all the tabs\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Testing Scraper\n",
    "test = details_scrape(\"https://www.guru.com/d/freelancers/lc/united-states/california/los-angeles/pg/1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = details_to_soup(test[0])\n",
    "b = details_to_soup(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = soup_urls_to_list(a)\n",
    "b2 = soup_values_to_list(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/freelancers/dugale', '/freelancers/mariana-franzetti', '/freelancers/alp-bakir', '/freelancers/super-writer-guy', '/freelancers/bplanningcom', '/freelancers/caes', '/freelancers/kathleen-keithley', '/freelancers/rachel-manning', '/freelancers/stuppi', '/freelancers/joy-david', '/freelancers/amykochjohnson', '/freelancers/michael-ramstead', '/freelancers/twchrist', '/freelancers/mimirose', '/freelancers/digital-industry', '/freelancers/xponential-outsourcery-inc', '/freelancers/yiran-zhang-1', '/freelancers/power-edits', '/freelancers/h9d-studio', '/freelancers/7-design-group']\n"
     ]
    }
   ],
   "source": [
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/freelancers/dugale', ' Aug, 2006', ' $35,176 ', '$173,052 ', '2 ', '89 ', ' $168,412 ']\n"
     ]
    }
   ],
   "source": [
    "c = combine_clean_data(a2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selen = combine_into_dataframe(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>member_since</th>\n",
       "      <th>earnings_pst_yr</th>\n",
       "      <th>earnings_ever</th>\n",
       "      <th>employers</th>\n",
       "      <th>invoices_paid</th>\n",
       "      <th>largest_employ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/freelancers/dugale</td>\n",
       "      <td>Aug, 2006</td>\n",
       "      <td>$35,176</td>\n",
       "      <td>$173,052</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>$168,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/freelancers/mariana-franzetti</td>\n",
       "      <td>Apr, 2019</td>\n",
       "      <td>$23,618</td>\n",
       "      <td>$23,618</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>$23,618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/freelancers/alp-bakir</td>\n",
       "      <td>Dec, 2019</td>\n",
       "      <td>$23,525</td>\n",
       "      <td>$23,525</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>$23,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/freelancers/super-writer-guy</td>\n",
       "      <td>Feb, 2008</td>\n",
       "      <td>$13,740</td>\n",
       "      <td>$57,024</td>\n",
       "      <td>205</td>\n",
       "      <td>527</td>\n",
       "      <td>$29,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/freelancers/bplanningcom</td>\n",
       "      <td>Dec, 2008</td>\n",
       "      <td>$6,230</td>\n",
       "      <td>$59,710</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>$16,400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              url member_since earnings_pst_yr earnings_ever  \\\n",
       "0             /freelancers/dugale    Aug, 2006        $35,176      $173,052    \n",
       "1  /freelancers/mariana-franzetti    Apr, 2019        $23,618       $23,618    \n",
       "2          /freelancers/alp-bakir    Dec, 2019        $23,525       $23,525    \n",
       "3   /freelancers/super-writer-guy    Feb, 2008        $13,740       $57,024    \n",
       "4       /freelancers/bplanningcom    Dec, 2008         $6,230       $59,710    \n",
       "\n",
       "  employers invoices_paid largest_employ  \n",
       "0        2            89       $168,412   \n",
       "1        1            24        $23,618   \n",
       "2        1            22        $23,525   \n",
       "3      205           527        $29,700   \n",
       "4       40            98        $16,400   "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selen.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
